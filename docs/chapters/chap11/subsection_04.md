[メインページ](../../index.markdown)

[章目次](./chap11.md)
## 11.4. 画像分類

画像分類は，画像をある特定のカテゴリに分類することを目的としている． 特にゼロショット，少数ショット，マルチラベルといった状況での画像分類に，グラフニューラルネットワークが用いられている． 本節では，これら3つの状況下でのGNNによる画像分類について，代表的なアルゴリズムを用いて説明する． 3.3.5節の図3.11に示したように，CNNを使った画像分類器は，通常2つの部分から構成される: 畳み込み層とプーリング層で構成される特徴抽出パートと, （一般に）全結合層でモデル化される分類パートである． 具体的には，この全結合層(ソフトマックス層なし)は行列 $\mathbf{W} \in \mathbb{R}^{d \times c}$ として表すことができる． ここで， $d$ は抽出された特徴料の次元， $c$ はタスクのカテゴリ数である．  $\mathbf{W}$ の $i$ 番目の行は $\mathbf{w}\_i$ で表され， $i$ 番目のカテゴリに対応する． これは与えられたサンプルが $i$ 番目のカテゴリに分類される確からしさを表す． 本節では， $\mathbf{w}\_i$ を $i$ 番目のカテゴリの「分類器」と呼ぶことにする．

### ゼロショット画像分類

コンピュータビジョン分野における画像分類タスクにおいて，伝統的にはカテゴリ分類器を学習するために，各カテゴリの豊富な画像が利用可能であるされてきた． 学習された分類器は，学習されたカテゴリからの画像しか認識できない． 新しいカテゴリの画像を認識するためには，そのカテゴリの数千枚の画像が必要となり，新たに収集した画像とともに対応する分類器を再学習させる必要があった． ゼロショット画像分類の課題は，学習画像を持たずに、カテゴリの説明や他のカテゴリとの関係などのカテゴリに関する情報のみに基づいて，新しいカテゴリに対する分類器を学習することである． (Wang et al., 2018b)では，ゼロショット画像分類に グラフニューラルネットワークが導入された: カテゴリ間の関係を記述した知識グラフを通じて他のカテゴリからの情報を伝播させることで，学習画像なしで分類器を学習する． 次に，まずゼロショット画像分類タスクの設定を定式化し, その後，グラフニューラルネットワークを使ってどのようにこの問題に取り組むのかを説明する．

ゼロショット画像分類では， $n$ 種類のカテゴリのデータセットが与えられ，始めの $m$ 種類のカテゴリには学習に十分な画像がある一方，残りの $n-m$ 種類のカテゴリには画像がない． 各カテゴリ $c_i$ には短い説明文と関連づけられており，これを使って言葉の意味を考慮した埋め込み表現 $\mathbf{x}\_i$ に落とし込むことができる． さらに，これらのカテゴリ間の関係を記述した知識グラフ(例えばWordNet (Miller, 1998)) $\symcal{G}=\{\symcal{V}, \symcal{E}\}$ を用いることができる(カテゴリはノードに対応). 本節の冒頭で，カテゴリ $c_i$ の「分類器」を表すために $\mathbf{w}\_i$ を使うことにした． 与えられたカテゴリ $c_i$ に対する，ロジスティック回帰のような線形分類器の場合にも, モデルパラメータ $\mathbf{w}\_i \in \mathbb{R}^{d}$ (d は入力画像の特徴量の次元)によってそのモデルを表すことができる． 画像が与えられたとき，その特徴量は事前に学習された畳み込みニューラルネットワークを用いて抽出することができる． 十分な学習サンプルを持つ $m$ 個のカテゴリについては，これらの学習サンプルを用いて，対応する分類器を学習することができる． ゼロショット画像分類タスクの目的は，画像のない $n-m$ 個のカテゴリに対して, それらの意味の埋め込み表現かつ(または)与えられた知識グラフ $\symcal{G}$ を利用して分類器を学習することである．

「(画像データのないカテゴリに対する)分類器を予測する」素直な方法としては，意味を考慮した，カテゴリの埋め込み表現を入力として，それに対応する分類器を出力するニューラルネットワークを用いることが考えられる． しかし実際には，十分な学習データがあるカテゴリの数は少ない場合が多く(数百のオーダー), ニューラルネットワークを学習させることができない． そこで，深層ニューラルネットワークの代わりに，グラフニューラルネットワークを用いて分類器を予測する． グラフニューラルネットワークを，カテゴリの埋め込み表現を入力とした知識グラフに適用することで，その出力はカテゴリに対応する分類器となる． Wang et al., (2018b)では，GCNフィルタ(5.3.2節参照)がグラフフィルタ処理として用いられ， $L$ 層のグラフフィルタ層積み重ねて特徴量(カテゴリの埋め込み表現が初めの特徴量)を絞り込んだ上で，最終的に分類器を得る． 具体的には，このタスクは回帰問題としてモデル化することができる． このモデル化では，最初の $m$ 個の分類器 $\left\\{\mathbf{w}\_1, \ldots, \mathbf{w}\_m\right\\}$ は正解として扱われている． (Wang et al., 2018b)では，層の数 $L$ は比較的大きな数(例えば6)に設定され，遠くの情報が知識グラフを通じて伝播されるようにする． しかし，経験上，グラフニューラルネットワークの層の数を増やすと性能が低下する可能性があることが示されている(Kampffmeyer et al., 2019)． そこで，性能を落とさずに遠くの情報を伝播あせるために，与えられた知識グラフから密なグラフを構築する． すべてのノードは，知識グラフ内のすべての先祖ノードに接続される． 構築された密なグラフをもとに2つのグラフフィルタ層が適用される: 1つ目の層では情報は子ノードから親ノードの方向にのみ集約され, 2つ目の層では情報は親ノードから子ノードの方向に流れる．

### 少数ショット画像分類

ゼロショット学習では，学習データなしに未知のカテゴリに対しる分類器を学習することを目的としていた． 少数ショット学習における画像分類では， $n$ 個のカテゴリが与えられ，このうち $m$ 個のカテゴリには学習に十分な画像が与えられるが，残りの $n-m$ 個のカテゴリでは $k$ 個のみのラベル付き画像が与えられる(ここで $k$ は通常3などの非常に小さい数である)． 特に $k=0$ のときには，ゼロショット画像分類タスクとして扱うことができる． 本節では特に， $k>0$ の場合に注目する．

少数ショット画像分類では，すべてのカテゴリがラベル付きの画像を持っている(データ量が学習に十分かどうかはおいておいて)ので，すべてのカテゴリについて分類器を学習することができる．  $i$ 番目のカテゴリについて学習された分類器を $\mathbf{w}\_i$ と書く． ラベル付けされた十分な学習画像を用いて学習された， $m$ 個のカテゴリについての分類器 $\left\\{\mathbf{w}\_1, \ldots, \mathbf{w}\_m\right\\}$ は，未知のデータサンプルに対する予測に使うことができる． しかし， $n-m$ 個のカテゴリについての分類器 $\left\\{\mathbf{w}\_{m+1}, \ldots, \mathbf{w}\_n\right\\}$ は，学習時に $k$ 個の学習画像しか存在せず，妥当な予測を行うには十分な分類器ではない可能性がある． したがって， $n-m$ 個のカテゴリについてよりよい分類器を学習することが目標となる．

11.4.1節で紹介したものと同様の方法で，分類器 $\left\\{\mathbf{w}\_{m+1}, \ldots, \mathbf{w}\_n\right\\}$ を改良することができる． 具体的には，これらの学習された分類器 $\left\\{\mathbf{w}\_{m+1}, \ldots, \mathbf{w}\_n\right\\}$ をGNNモデルの入力として使うことで，改良版分類器を生成する． このGNNモデルは十分なラベル付きデータを持つカテゴリで学習させることができる(Gidaris and Komodakis, 2019)． 特に，あまり学習されていない分類器を改良するプロセルを真似するため，十分な学習データがある各カテゴリについて， $k$ 個の学習データをサンプル抽出して偽の学習データセットを作成することで，ラベル付きデータが $k$ 個しかないカテゴリの状況を再現する． 次に，この偽の学習データセットから分類器 $\left\\{\hat{\mathbf{w}}\_1, \ldots, \hat{\mathbf{w}}\_m\right\\}$ を学習する． そしてこれらの偽の分類器 $\left\\{\hat{\mathbf{w}}\_1, \ldots, \hat{\mathbf{w}}\_m\right\\}$ を用いてGNNモデルを学習する． このGNNモデルは11.4.1節のものと同様のもので，違いは単語の埋め込み表現を入力に用いるのではなく，ここでは偽の分類器を入力に用いている点である． 11.4.1節で述べたように，カテゴリ間の関係性を記述する知識グラフをグラフとして用いて，そこにGNNモデルを適用する． (Gidaris and Komodakis, 2019)では，カテゴリ間のグラフは，改良前の分類器同士の類似性を元に構築される．

### マルチラベル画像分類

マルチラベルの画像分類の課題は，与えられた画像に表示されている物体集合を予測することである． そのための簡単な方法としては，この問題を2値分類問題の集合として扱うことである． 各2値分類器は，ある物体が画像内に存在するかどうかを予測する． しかし，実際の世界では，頻繁に一緒に存在する物体がある． 例えば，テニスボールとテニスラケットはよく一緒に出てくる． 物体間の依存関係を捉えることは，マルチラベル画像分類の成功の鍵となる． (Chen et al., 2019c)では，学習データから物体間の関係を記述するグラフを学習し，グラフニューラルネットワークをこのグラフに適用することで, 相互に依存する分類器を学習する． この分類器は与えられた画像内に物体があるかどうかを予測する． 11.4.1節と同様に，分類器をベクトル $\mathbf{w}\_i$ で表す．

与えられた画像 $I$ について，マルチラベル画像分類の目標は，物体候補の集合 $\symcal{C}=\left\\{c_1, \ldots, c_K\right\\}$ のうちどの物体が与えられた画像に現れているかを予測することである． したがって，このタスクを実行するためには $K$ 個の2値分類器( $\left\\{\mathbf{w}\_1, \ldots, \mathbf{w}\_K\right\\} \text {, with } \mathbf{w}\_i \in \mathbb{R}^{d}$ )の集合を学習する必要がある． 分類器の次元 $d$ は画像の表現 $\mathbf{x}\_I \in \mathbb{R}^{d}$ (事前学習済のCNNによって抽出できる)によって定義される． 物体間の相互依存関係を捉えるような分類器を学習するため，物体間の関係性を記述するグラフ $\symcal{G}$ にグラフニューラルネットワークモデルが適用される． (Chen et al., 2019c)では，グラフ $\symcal{G}$ は物体をノードとして構成されており，それらのつながりは学習データにおける共起性に基づいて構成される． 具体的には，まず学習画像中の任意の物体のペアについて，共起数(例えば，画像中で一緒に出現した回数)を数えることで, 行列 $\mathbf{M} \in \mathbb{R}^{K \times K}$ を得る． ここで， $\mathbf{M}\_{i,j}$ は $i$ 番目と $j$ 番目の物体の共起数を表す． 次に，この行列の各行を次のように規格化する:

 $$
 \mathbf{P}_i=\mathbf{M}_i / N_i
    \nonumber $$
 

ここで， $\mathbf{P}\_i$ と $\mathbf{M}\_i$ はそれぞれ行列 $\mathbf{P}, \mathbf{M}$ の $i$ 行目を表し， $N_i$ は $i$ 番目の物体の出現回数を表す． 行列 $\mathbf{P}$ をスパース化するため，閾値 $\tau$ を設定してノイズの多いエッジをフィルタする:

 $$
 \boldsymbol{A}_{i, j}=
    \begin{cases}
    0, & \text { if } \boldsymbol{P}_{i, j}<\tau \\ 1, & \text { if } \boldsymbol{P}_{i, j} \geq \tau          
    \end{cases}
    \nonumber $$
 

行列 $\mathbf{A}$ は構成したグラフの隣接行列とみなすことができる． グラフが構成されると，グラフニューラルネットワークモデルを適用することで，それぞれの物体用の分類器を学習することができる． 具体的には，物体の分類器はグラフニューラルネットワークモデルの出力である． なお，入力はこれらの物体の単語の埋め込み表現である． 分類器 $\left\\{\mathbf{w}\_1, \ldots, \mathbf{w}\_K\right\\}$ を得た後，画像の表現 $\mathbf{x}\_I$ をスコア $\mathbf{w}\_i^{T} \mathbf{x}\_I$ (各物体 $c_i$ の2値分類に使うことができる)に射影することで分類を行うことができる． なお，全体の処理としては入力の画像から出力の予測結果まで一気に直接学習しているモデルである．


[メインページ](../../index.markdown)

[章目次](./chap11.md)

[前の節へ](./subsection_03.md) [次の節へ](./subsection_05.md)


