[メインページ](../../index.markdown)

[章目次](./chap7.md)
## 7.4. 部分グラフごとのサンプリング

層ごとのサンプリング方法では，最終的なノード表現の計算に関わるノード数を大幅に削減し，近傍爆発の問題を解決することができる． しかし，層ごとのサンプリングの性質上，層から層に集約する際に別の問題を引き起こす可能性がある． 具体的には，式(7.18)において， $\mathbf{F}\_i^{(l)}$ を生成するための集約処理がこれから集約される，サンプリングされた各ノードの $\hat{\mathbf{A}}\_{i, j}$ に依存しているということだである． このことから $\mathbf{F}\_i^{(l)}$ を生成するために $N^l$ 中のすべてのノードが使われるわけではなく，ノード $v_i$ とつながりをもつノードのみが使われるということがわかる． もしノード $v_i$ と $N^l$ 中のサンプリングされたノードの間のつながりが非常にスパースだった場合，ノード $v_i$ の表現 $\mathbf{F}\_i^{(l)}$ はうまく学習できない可能性がある． 極端な場合，ノード $v_i$ とつながりをもつノードが $N^l$ 中に存在しないときには, 式(7.18)にしたがうと，この層のノード $v_i$ の表現は0になってしまう． したがって学習中の安定性を改善させるためには，ノード $v_i$ にある程度つながっている $N^l$ をサンプリングする必要がある． つまり， $N^l$ と $N^{l-1}$ のサンプリングされたノード間の接続を密にして, すべてのノードに情報を集約する元のノードが存在するようにしておく必要がある． 7.3節で述べた層ごとのサンプリング方法では，層ごとのサンプリング分布を設計する際にこの点を考慮していない． 連続する層のサンプリングされたノード間の接続を改善するためには, 連続する層のサンプリング分布を互いに依存するように設計する必要があるが，これは非常に難しい． 全ての層で同じサンプリングされたノード集合を用いることで，分布つくるのが簡単になる． つまり， $l=L \ldots, 2$ について， $N^{l}=N^{l-1}$ とする． サンプリングされたノード間がよりつながりやすくなるように, 1つだけサンプリング分布を作り出せばよい． さらに，すべての層について同一のノード集合 $\symcal{V}\_s$ を採用したとすると，式(7.18)の層ごとの集約は，サンプルしたノード集合 $\symcal{V}\_s$ 上のグラフ $\symcal{G}\_s=\left\\{\symcal{V}\_s, \symcal{E}\_s\right\\}$ について，すべての近傍ノードの集計をしていることになる． このようにして生成された誘導グラフ $\symcal{G}\_s$ は元のグラフ $\symcal{G}$ の部分グラフなっている． というのも，ノードもエッジも元のグラフの部分集合になっているからである( $\symcal{V}\_s \subset \symcal{V}, \symcal{E}\_s \subset \symcal{E}$ )． 各バッチごとに $\symcal{V}\_s$ をサンプリングする代わりに， $\symcal{G}$ から直接部分グラフ $\symcal{G}\_s$ をサンプリングして，部分グラフ上でモデルの学習を行う． このようにノード表現を取得するために部分グラフをサンプリングしモデルの学習を行う方法を「部分グラフごとのサンプリング」と呼ぶ． 部分グラフごとのサンプリング方法には，ことなる部分グラフ $\symcal{G}\_s$ に注目した様々な方法がある(Chiang et al., 2019; Zeng et al., 2019)．

(Chiang et al., 2019)では，METIS (Karypis and Kumar, 1998)やGraclus(Dhillon et al., 2007)などのグラフクラスタリングを使って，各クラスター内のつながりが，クラスター同士のつながりよりもはるかに大きくなるように，グラフ $\symcal{G}$ から部分グラフ（クラスター） $\{\symcal{G}\_s\}$ を切り分けている． SGDを適用するため， $\{\symcal{G}\_s\}$ から毎回部分グラフをサンプリングし，次の損失関数に基づいて勾配を計算する:

 

$$
 \symcal{L}_{G_s}=\sum_{v_i \in \symcal{V}_I \cap \symcal{V}_s} \ell\left(f_{G N N}\left(\mathbf{A}_s, \mathbf{F}_s ; \boldsymbol{\Theta}\right)_i, y_i\right) $$


 

ここで, $\mathbf{A}\_s$ と $\mathbf{F}\_s$ はそれぞれ隣接行列とサンプリングされた部分グラフ $\symcal{G}\_s$ の特徴量である． 集合 $\symcal{V}\_I \cap \symcal{V}\_s$ は $\symcal{V}\_s$ 中のラベル付きのノードからなる． このサンプリングされた部分グラフ $\symcal{G}\_s$ 上でSGDを1ステップ行うのに必要なメモリは $O\left(\left\|\symcal{E}\_s\right\|+L \cdot\left\|\symcal{V}\_s\right\| \cdot d+L \cdot d^{2}\right)$ である．

(Zeng et al., 2019)では，部分グラフ $\symcal{G}\_s$ が誘導されるノード集合 $\symcal{V}\_s$ をサンプリングするために様々なノード抽出法が提案されている． 具体的には，エッジーに基づいたノード抽出法は，互いに強く影響し合うノードをペアとしてサンプルするように設計されており, ランダムウォークに基づいた方法では，サンプリングされたノード間がより接続するように設計されている． これら2つについて簡単に説明する．

-   **エッジベース抽出**

    以下の分布に従って $m$ 個のエッジをランダムにサンプリングする:

     

$$
 p((u, v))=\frac{\left(\frac{1}{d(u)+d(v)}\right)}{\sum_{\left(u^{\prime}, v^{\prime}\right) \in \symcal{E}}\left(\frac{1}{d\left(u^{\prime}\right)+d\left(v^{\prime}\right)}\right)} $$


  ここで， $d(v)$ はノード $v$ の次元を表す． サンプリングされたノード集合 $\symcal{V}\_s$ は $m$ 個のサンプリングされたエッジの端点のノードから構成され，部分グラフ $\symcal{G}\_s$ を誘導する．

-   **RWベース抽出**

     $\symcal{V}$ から $r$ 個の根ノード群を一様にサンプル（復元抽出）する． サンプリングされた各ノードから出発してランダムウォークを生成する． ランダムウォークでたどり着いたノードから最終的なサンプリングされたノード集合 $\symcal{V}\_s$ を構成し, 部分グラフ $\symcal{G}\_s$ を誘導する．

集約処理においては，バイアスを減らすため正規化が行われる:

 

$$
 \mathbf{F}_i^{(l)}=\sum_{v_j \in \symcal{V}_s} \frac{\hat{\symbf{A}}_{i, j}}{\alpha_{i, j}} \mathbf{F}_j^{(l-1)} \Theta^{(l-1)} $$


 

ここで， $\alpha_{i, j}$ はサンプリングされた部分グラフから推定される． 具体的には， $M$ 個の部分グラフの集合について， $C_i$ と $C_{i,j}$ をノード $v_i$ とエッジ $(v_i, v_j)$ が $M$ 個のグラフに現れる回数とし， $\alpha_{i, j}$ を $C_{i,j}/C_i$ で推定する． さらに，サンプリングされた部分グラフ $\symcal{G}\_s$ に基づくミニバッチの損失関数も次のように正規化する:

 

$$
 \symcal{L}_{G_s}=\sum_{v_i \in \symcal{V}_l \cap \symcal{V}_s} \frac{1}{\lambda_i} \ell\left(f_{G N N}\left(\mathbf{A}_s, \mathbf{F}_s ; \boldsymbol{\Theta}\right)_i, y_i\right) $$


 

ここで， $\lambda_i$ は $C_i/M$ で推定できる． この正規化によっても損失関数のバイアスを減らすことができる．


[メインページ](../../index.markdown)

[章目次](./chap7.md)

[前の節へ](./subsection_03.md) [次の節へ](./subsection_05.md)


