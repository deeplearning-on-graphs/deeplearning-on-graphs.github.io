[メインページ](../../index.markdown)

[章目次](./chap7.md)
## 7.5. 本章のまとめ

本章では，グラフニューラルネットワークモデルのスケーラビリティを向上させるためのサンプリング方法について議論した． 初めに，グラフニューラルネットワークモデルの学習において確率的勾配降下法（SGD）が機能しなくなる, 「近傍爆発」問題を紹介した． 次に，ノードごとのサンプリング，層ごとのサンプリング，部分グラフごとのサンプリングという3種類のサンプリング手法を紹介した． これらの方法は，ミニバッチSGDの順伝搬パスにおいて，計算に関係するノード数を減らし，スケーラビリティを向上させることを目的としている． 各アルゴリズムについて，その長所と短所を論じ，代表的なアルゴリズムを紹介した．


[メインページ](../../index.markdown)

[章目次](./chap7.md)

[前の節へ](./subsection_04.md) [次の節へ](./subsection_06.md)


