# 3. 深層学習の基礎

## 3.1 はじめに

機械学習とは, 明示的にプログラムすることなく,
サンプルデータからコンピュータに適切な動作を学習させる研究分野である.
そして深層学習とは,
ニューラルネットワーク上に構成された機械学習アルゴリズムの一種である.
実は, 深層学習の主要な構成要素のほとんどは数十年前から存在していたが,
深層学習が普及したのは近年のことである.
ニューラルネットワークのアイデアは, McCulloch-Pitts Neuron（McCulloch
and Pitts, 1943）が初めて紹介された1940年代にさかのぼる.
この線形モデルは, 入力からの情報を線形に集約することで,
入力が2つのカテゴリのうちどちらからか判断することができる. その後,
ローゼンブラット（1958）がパーセプトロンを開発し,
これによって学習サンプルを与えてパラメータを学習することができるようになった.
ニューラルネットワークの研究が再び流行りだしたのは1980年代のことである.
この時期の大きなブレークスルーの1つは, 逆伝搬法（Rumelhartら, 1986年, Le
Cun and Fogelman-Soulie ́, 1987年）を用いて,
ディープニューラルネットワークモデルの学習に成功したことである. なお,
逆伝搬法は1960年代から多くの先行研究があり,
Werbosがニューラルネットワークの学習に初めて応用している（Werbos,
1994）. 逆伝搬法は深層学習の時代である現代においても,
深層モデルを学習するためのアルゴリズムとして主流となっている.
深層学習の研究は,
近年の「ビッグデータ」と強力な計算資源の利用が可能になったことで再び流行し,
かつてないほどの注目を集めた. 高速なGPUの登場により,
非常に大きなサイズの深層モデルを学習することが可能になった.
ますます大きくなるデータにより,
これらのモデルが十分に一般化できることが保証された. この2つの利点により,
様々な研究分野で深層学習技術が大成功を収め,
現実世界に多大な影響を与える結果となった.
ディープニューラルネットワークは, 様々なアプリケーションにおいて,
最先端の従来の手法を大差で凌駕している. 深層学習は,
画像認識タスクのパフォーマンスを大幅に向上させた. ImageNet Large-Scale
Visual Recognition Challengeは, 画像認識における最大のコンテストで,
2010年から2017年まで毎年開催された. 2012年には,
畳み込みニューラルネットワーク（CNN）が,
トップ5のエラー率を26.1％から15.3％に減らすという大差で,
このチャレンジで初めて優勝した（Krizhevsky et al., 2012）.
それ以降はCNNが安定して優勝しており,
誤差率はさらに3.57％まで減少している（He et al., 2016）. また,
深層学習は音声認識システムの性能を飛躍的に向上させている（Dahl et
al.2010, Deng et al.2010, Seide et al.2011）.
深層学習技術を音声認識に導入したことで,
長年停滞していたエラー率が大きく低下した. 自然言語処理の研究分野も,
深層学習技術によって大きく加速されている. LSTM（Hochreiter and
Schmidhuber, 1997）などのリカレントニューラルネットワークは,
機械翻訳（Sutskever et al., 2014; Bahdanau et al.,
2014）や対話システム（Vinyals and Le,
2015）などの配列対配列のタスクで広く利用されている.
「グラフ上の深層学習」の研究は深層学習に根ざしているため,
いくつかの基本的な深層学習の技術を理解することが不可欠である.
そこで本章では, 順伝搬型ネットワーク, 畳み込みネットワーク（CNN）,
リカレントネットワーク（RNN）, オートエンコーダーなど,
グラフ上の深層学習を研究する上で基礎となる重要な深層学習技術を簡単に紹介する.
本章では基本的な深層モデルに焦点を当てているが,
後の章では変分オートエンコーダー（VAE）や敵対的生成ネットワーク（GAN）などのより高度な深層モデルに議論を広げていく.

## 3.2 深層順伝播型ネットワーク

順伝播型ネットワークは, 多くの重要な深層学習技術の基礎となっている.
このネットワークは与えられたデータを用いて関数$f^{\ast}(x)$を近似する.
例えば分類問題において,
理想的な分類器である$f^{\ast}(x)$は与えられた入力$\mathbf{x}$を正解の分類$\mathbf{y}$に対応づける.
この場合,
順伝播型ネットワークでは理想的な分類器$f^{\ast}(x)$をうまく近似できるような写像$f(\mathbf{x} \mid \Theta)$を見つける.
具体的には, 順伝播型ネットワークを学習する目的は,
$f^{\ast}(x)$の最良の近似値を得ることができるパラメータ$\Theta$の値を学習するということになる.

順伝播型ネットワークでは,
情報$\mathbf{x}$が入力からいくつかの中間計算を経て,
最終的に出力$\mathbf{y}$に流れる.
これらの途中過程はネットワークの形をしており,
通常いくつかの関数の組み合わせとして表現される. 例えば,
の順伝播型ネットワークは,
4つの関数$f^{(1)}, f^{(2)}, f^{(3)}, f^{(4)}$が鎖状に接続されており,
これらの関数を用いて$f(\mathbf{x})$は$f(\mathbf{x})=f^{(4)}\left(f^{(3)}\left(f^{(2)}\left(f^{(1)}(\mathbf{x})\right)\right)\right)$と表される.
の順伝播型ネットワークでは, $f^{(1)}$が第1層, $f^{(2)}$が第2層,
$f^{(3)}$が第3層, そして最後の層$f^{(4)}$が出力層となっている.
ネットワークの計算層の数でネットワークの深さが決まる.
ニューラルネットワークは, 出力$f(x)$を理想的な出力,
すなわち$f^{\ast}(x)$またはyに近づけようと学習する. 学習過程において,
出力層からの結果は直接学習データと比較される一方で,
全ての中間層はそうではない. したがって,
理想的な関数$f^{\ast}(x)$をうまく近似するためには,
出力層から伝搬してくる間接的な情報を用いて中間層のパラメータを決定する.
中間層は, 学習時には学習データから望ましい出力が得られないため,
隠れ層と呼ばれている. 前述のように,
ニューラルネットワークの各層は入力と出力の両方がベクトルであるベクトル値関数とみなすことができる.
層の要素はノード(またはユニット)として扱うことができる. このように,
各層は,
各ノードが関数であるベクトルをスカラーに対応させる関数の集まりと考えることができる.
このようなネットワークは,
神経科学の言葉を借りてニューラルネットワークと呼ばれている.
ノードでの操作は, 脳のニューロンで起きていることを真似ており,
十分な刺激を受けたときに活性化する. ノードは,
前の層のすべてのノードから情報を集めて変換し, 活性化関数に送し,
次の層に情報をどの程度まで通過させるかを決める.
情報の収集と変換の操作は一般的に線形だが,
活性化関数はニューラルネットワークに非線形性を加え,
これによって近似能力が大きく向上する.

<figure id="fig:FFN">
<img src="chapters/chap3/fig/fig3_1.png" />
<figcaption>順伝播型ネットワークの例</figcaption>
</figure>

### ネットワークの構成

全結合型の順伝播型ニューラルネットワークでは，連続した層のノードは完全な二部グラフを形成している.
は，このネットワーク構成の全体像を表す. 次に,
ニューラルネットワークで行われる計算の詳細を述べる. ここでは,
第1層の1つのノードに注目する.
ニューラルネットワークの入力は，ベクトル$\mathbf{x}$で，$x_i$はそのi番目の要素を表す.
これらの要素はすべて入力層のノードとみなすことができる.
第2層のノード(または入力層の次の層のノード)は，入力層のすべてのノードに接続されている.
これらの入力層のノードと第2層の任意のノードとの接続をに示す.

<figure id="fig:fig3_2">
<img src="chapters/chap3/fig/fig3_2.png" />
<figcaption>ノードでの操作</figcaption>
</figure>

1つのノードにおける演算は, 次の2つの部分から構成される:

1.  入力を重み（$\mathbf{w}_{i}$）で線形に組み合わせる

2.  前のステップで得られた値を, 活性化関数に通す

これは数学的には次のように書くことができる：
$$h=\alpha\left(b+\sum_{i=1}^{4} \mathbf{w}_{i} \cdot \mathbf{x}_{i}\right)\nonumber$$
ここで, $b$はバイアス項, $\alpha$は活性化関数（次の章で述べる）を表す.
次にこの演算を任意の隠れ層に一般化する.
ニューラルネットワークのk番目の層には$N^{(k)}$ノードあり,
その出力は$\mathbf{h}^{(k)}$と表すことができるとする（ここで,
$\mathbf{h}^{(k)}_{i}$はi番目の要素を表す）.
ニューラルネットワークのk+1番目の層で$\mathbf{h}^{(k+1)}$を計算するために次の演算を行う：
$$\mathbf{h}_{j}^{(k+1)}=\alpha\left(b_{j}^{(k)}+\sum_{i=1}^{N^{(k)}} \mathbf{W}_{j i}^{(k)} \mathbf{h}_{i}^{(k)}\right)\label{eq:3_1}$$
ここで,
$\mathbf{W}_{j i}^{(k)}$は$\mathbf{h}_{i}^{(k)}$と$\mathbf{h}_{i}^{(k+1)}$をつなげる重みに対応し,
$b_{j}^{(k)}$はバイアス項を表す.
k+1層の全要素を計算する演算を行列形式で書くと次のようになる：
$$\mathbf{h}^{(k+1)}=\boldsymbol{\alpha}\left(\mathbf{b}^{(k)}+\mathbf{W}^{(k)} \mathbf{h}^{(k)}\right)\nonumber$$
ここで,
$\mathbf{W}^{(k)} \in \mathbb{R}^{N^{(k+1)} \times N^{(k)}}$は全てのウェイトを含み,
(j, i)要素は[\[eq:3_1\]](#eq:3_1){reference-type="eqref"
reference="eq:3_1"}の$\mathbf{W}_{j i}^{(k)}$である.
$\mathbf{b}^{(k)}$は全てのバイアス項を含む. 特に,
入力層においては$\mathbf{h}^{(0)}=\mathbf{x}$となる.
ニューラルネットワークのk+1層目の演算を表すのに$f^{k+1}$を使っていたことを思い出すと,
$$\mathbf{h}^{(k+1)}=f^{(k+1)}\left(\mathbf{h}^{(k)}\right)=\alpha\left(\mathbf{b}^{(k)}+\mathbf{W}^{(k)} \mathbf{h}^{(k)}\right)\nonumber$$
と書くことができる.
ここで紹介した演算は隠れ層において典型的なものである.
出力層も同様の構造であるが,
得られた情報を変換するための活性化関数が異なっていることが多い. 次に,
活性化関数と出力層の設計について述べる.

### 活性化関数 {#sec:3.2.2}

活性化関数は, 入力信号を通過させるかどうか, あるいはどの程度通過させ
るかを決定する. ノード(またはニューロン)は,
そこを通過する情報があれば活性化される. 前節で紹介したように,
活性化関数がない場合には, ニューラルネットワークの演算は線形になる.
活性化関数は, ニューラルネットワークに非線形性を導入し,
それによって近似能力が向上する. 以下では,
よく使われている活性化関数を紹介する.

#### ReLU関数 {#relu関数 .unnumbered}

ReLU関数は最もよく使われる活性化関数の一つである. に示すように,
ReLU関数は線形関数と似ているが,
入力が負のときに0を出力する点が唯一異なる. ニューラルネットワークでは,
この活性化関数を採用したユニットをRectifier Linear Unit (ReLU)と呼ぶ.
ReLU関数はすべての正の入力に対して線形（というより同じ値を出力する）であり,
すべての負の入力に対して0である. 数学的には次のように定義される：

$$\operatorname{ReLU}(z)=\max \{0,  z\}\nonumber$$

<figure id="fig:fig3_3">
<img src="chapters/chap3/fig/fig3_3.png" />
<figcaption>ReLU関数</figcaption>
</figure>

各層では, いくつかのユニットのみが活性化されるため, 効率的な計
算が可能になる. ReLU関数の欠点は,
入力が負の領域で勾配が0になることである. したがって,
ユニットが活性化されないと,
そのユニットを訓練するための情報が伝搬しなくなってしまう.
この欠点を克服するために, ReLU関数のいくつかの一般化が提案されている.
LeakyReLU関数 (Maas et al., 2013)は, 負の入力を0にする代わりに, (a)に
示すように, 負の値に対して小さな傾きを持つ線形変換を行う.
より具体的には, LeakyReLU関数は数学的に次のように表すことができる：

$$\operatorname{LeakyReLU}(z)=\left\{\begin{array}{cc}0.01 z & z<0 \\ z & z \geq 0\end{array}\right.\nonumber$$

<figure id="fig:fig3_4">
<img src="chapters/chap3/fig/fig3_4.png" />
<figcaption>ReLU関数の一般化</figcaption>
</figure>

ReLU関数をさらに一般化したものが, ELU関数 (Exponential Linear
Unit)である. ELU関数は(b)に示すように, 正の値に対しては恒等変換を行うが,
負の値に対しては指数関数的な変換を行う. 数学的には,
ELUの活性化関数は次のように表される：
$$\operatorname{ELU}(z)=\left\{\begin{array}{cc}c \cdot \exp (z-1) & z<0 \\ z & z \geq 0\end{array}\right.\nonumber$$
ここで, $c$は負の入力に対して指数関数の傾きを決める正の定数である.

#### ロジスティックシグモイド関数とtanh関数 {#ロジスティックシグモイド関数とtanh関数 .unnumbered}

活性化関数としては,
ReLU関数よりも先にロジスティックシグモイド関数とtanh関数が最もよく使われてきた.
ロジスティックシグモイド関数は数学的には次のように表される：
$$\sigma(z)=\frac{1}{1+\exp (-z)}\nonumber$$

<figure id="fig:fig3_5">
<img src="chapters/chap3/fig/fig3_5.png" />
<figcaption>ロジスティックシグモイド関数とtanh関数</figcaption>
</figure>

(a)に示すように, シグモイド関数は入力を0から1の範囲に変換する.
具体的には, 入力が負の値であるほど出力は0に近づき,
入力が正の値であるほど出力は1に近づくことになる.

tanh関数はシグモイド関数と次のような関係がある：
$$\tanh (z)=\frac{2}{1+\exp (-2 z)}-1=2 \cdot \sigma(2 z)-1\nonumber$$

(b)に示すように, tanh関数は入力を-1から1の範囲に変換する. 具体的には,
入力が負の値であるほど出力は-1に近くなり,
入力が正の値であるほど出力は1に近づく.

この2つの活性化関数は,
サチュレーション問題という同じ問題に直面している(Nwankpa et al.).
入力$z$が巨大な正の数または負の数である場合に出力が一定に近づいてしまう.
つまり, この活性化関数は0に近い値にしか感度がない.
$z$が巨大な正の数または負の数である場合には勾配が0付近になるため,
勾配ベースの学習が非常に難しくなる. このような理由から,
この2つの活性化関数は順伝搬型ネットワークではあまり使われなくなってきている.

### 出力層と損失関数

出力層と損失関数は, どのようなタスクに適用するかによって異なる. 次に,
一般的に使用される出力ユニットと損失関数を紹介する.

回帰問題では, ニューラルネットワークは連続値を出力する必要がある.
これを実現する簡単な方法は, 非線形活性化を行わずに,
アフィン変換を行うことである.
入力(または前の層からの情報)が$\mathbf{h} \in \mathbb{R}^{d_{i n}}$であるとき,
線形ユニットの層は,
ベクトル$\hat{\mathbf{y}} \in \mathbb{R} d_{o u}$を次のように出力する：
$$\hat{\boldsymbol{y}}=\boldsymbol{W h}+\boldsymbol{b}\nonumber$$
ここで,
$\mathbf{W} \in \mathbb{R}^{d_{o u} \times d_{i n}}$と$\mathbf{b} \in \mathbb{R}^{d_{o u}}$は学習すべきパラメータである.
一つのサンプルに対して,
予測値$\hat{\boldsymbol{y}}$と正解$\boldsymbol{y}$との差を測定するために,
以下のように単純な二乗損失関数を用いることができる：
$$\ell(\mathbf{y},  \hat{\mathbf{y}})=(\mathbf{y}-\hat{\mathbf{y}})^{2}\nonumber$$

分類問題では,
ニューラルネットワークは与えられたサンプルのクラスの情報が必要になる.
与えられたサンプルの予測ラベルにあたる離散的な値をを直接出力する代わりに,
通常は, ラベルに対する離散的な確率分布を出力する.
予測対象が二値か多値かによって, 異なる出力層と損失関数が使われる. 次に,
この2つの場合の詳細について述べる.

#### 二値分類 {#二値分類 .unnumbered}

2値分類のタスクでは,
サンプルは0か1のどちらかにラベル付けされていると仮定する.
そして予測を行うために,
まず入力（前の層からの結果）を一つの値に変換する線形層が必要である.
続いて, シグモイド関数を適用して, この値を0から1の範囲に対応させる.
これはサンプルがラベル1として予測される確率に対応する. まとめると,
この処理は次のようにモデル化できる：
$$\hat{y}=\sigma(\mathbf{W h}+b)\nonumber$$ ここで,
$\mathbf{h} \in \mathbb{R}^{d_{i n}}$および$\mathbf{W} \in \mathbb{R}^{1 \times d_{i n}}$である.
特に, $\hat{y}$は入力サンプルがラベル1と予測される確率を示し,
$1-\hat{y}$はラベル0と予測される確率を表す. 出力$\hat{y}$を用いると,
交差エントロピー損失関数を用いることで,
正解値と予測値の差を次のように計算することができる：
$$\ell(y,  \hat{y})=-y \cdot \log (\hat{y})-(1-y) \cdot \log (1-\hat{y})\nonumber$$
モデルを用いて推論する際には,
$\hat{y}>0.5$の時に入力サンプルはラベル1と予測され,
そうではない時にラベル0と予測される.

#### 多値分類 {#多値分類 .unnumbered}

多クラス(nクラス）の分類課題では,
正解はは0からn-1までの整数で表されると仮定する. そこで,
分類ラベルを表現するためにOne-hotベクトル$\mathbf{y} \in\{0, 1\}^{n}$を用いる.
ここで$\mathbf{y}_{i}=1$はサンプルが$i-1$とラベル付けされていることを表す.
予測を行うために,
まず入力$\mathbf{h}$をn次元ベクトル$\mathbf{Z} \in \mathbb{R}^{n}$に変換する線形層が必要である：
$$\mathbf{z}=\mathbf{W}\mathbf{h}+\mathbf{b}\nonumber$$ ここで,
$\mathbf{W} \in \mathbb{R}^{n \times d_{i n}}$および$\mathbf{b} \in \mathbb{R}^{n}$である.
次に, ソフトマックス関数に入力し,
$z$を全クラスに渡って離散的な確率密度関数に標準化する：
$$\hat{\mathbf{y}}_{i}=\operatorname{softmax}(z)_{i}=\frac{\exp \left(\mathbf{z}_{i}\right)}{\sum_{j} \exp \left(\mathbf{z}_{j}\right)},  i=1,  \ldots,  n\nonumber$$
ここで, $\mathbf{z}_{i}$はベクトル$z$のi番目の要素を表し,
$\hat{\mathbf{y}}_i$はソフトマックス関数のi番目の出力を表す. 特に,
$\hat{\mathbf{y}}_i$は入力サンプルがラベル$i-1$で予測される確率を表す.
予測値
$\hat{\mathbf{y}}$に対して，交差エントロピー損失関数を用いることで,
正解値と予測値の差を計算することができる：
$$\ell(\mathbf{y},  \hat{\mathbf{y}})=-\sum_{i=0}^{n-1} \mathbf{y}_{i} \log \left(\hat{\mathbf{y}}_{i}\right)\nonumber$$
モデルを用いて推論する際には,
$\hat{\mathbf{y}}_i$が$\hat{\mathbf{y}}$のn個の要素の中で最も大きい時に入力サンプルはラベル$i-1$と予測される.

## 畳み込みニューラルネットワーク

CNN(Convolutional Neural Networks)は,
よく使われているニューラルネットワークの一種であり,
画像などの規則的な格子状のデータを処理するのに適している.
CNNは多くの点で順伝播型ニューラルネットワークと似ている.
学習可能な重みとバイアスを持つニューロンで構成されており,
各ニューロンは前の層からいくつかの情報を受け取って変換する.
CNNが順伝播型ニューラルネットワークと異なる場合があるのは,
CNNのいくつかのニューロンの構造である. より具体的には,
ニューロンを構成する際に畳み込み演算が導入されている点である.
このような畳み込み演算を行う層を畳み込み層と呼ぶ. 畳み込み演算は通常,
前の層の少数のニューロンの情報のみを使い,
層間の接続を疎にすることができる.
CNNにおけるもう一つの重要な操作はプーリング操作で,
これは近くのニューロンの出力をまとめて新しい出力とする.
プーリング演算を行う層をプーリング層と呼ぶ. この節では,
まず畳み込み演算と畳み込み層について紹介し,
次にプーリング層について議論し, 最後にCNNの全体的な枠組みを述べる.

### 畳み込み演算と畳み込み層

一般に, 畳み込み演算は,
2つの実関数に対して第3の関数を生成する数学的演算である（Widder and
Hirschman, 2015）.2 つの関数$f ()$ と $g ()$ の間の畳み込み演算は,
以下のように定義できる：

$$(f * g)(t)=\int_{-\infty}^{\infty} f(\tau) g(t-\tau) d \tau\nonumber$$

畳み込み演算を具体的に理解するために, 連続的な信号$f(t)$を考える.
ここで, $t$は時間, $f(t)$は時間$t$における対応する値である.
この信号がいくらかノイズを含んでいるとする.
ノイズの少ない信号を得るために, 時刻$t$の値とその近傍の値を平均化したい.
さらに, $t$に近い時間帯の値は, $t$の値と類似している可能性があり,
より多く寄与するはずである. そこで,
時刻$t$に近いいくつかの値の加重平均を新しい値にする.
これは信号$f(t)$と重み関数$w(c)$の畳み込み演算としてモデル化することができる.
畳み込み演算後の信号は, 以下のように表すことができる：
$$s(t)=(f * w)(t)=\int_{-\infty}^{\infty} f(\tau) w(t-\tau) d \tau\nonumber$$

なお, この演算が加重平均を行うことを保証するために,
$w(c)$は積分して1になるように制約されているので,
$w(c)$は確率密度関数となる. 一般には,
畳み込み演算は加重平均である必要はなく,
関数$w(t)$はこれらの要件を満たす必要はない.

実際には, データは一定の間隔を持った離散的なものであることが多い.
例えば, 信号 $f (t)$ は時間 $t$
の整数値でしかサンプリングされないことがある. 先ほどの例の$f ()$と
$w()$がともに時間 $t$の整数値で定義されているとすると,
畳み込みは次のように書くことができる：
$$s(t)=(f * w)(t)=\sum_{\tau=-\infty}^{\infty} f(\tau) w(t-\tau)\nonumber$$
さらに, ほとんどの場合,
関数$w()$は小さなウィンドウ幅でしか非ゼロにならない. 言い換えれば,
局所的な情報のみが畳み込む場所の新しい値に寄与する.
ウィンドウ幅が$2n＋1$, すなわち,
$c＜n$と$c＞n$で$w（c）＝0$であるとすると,
畳み込みはさらに次のように書き換えることができる.
$$(f * w)(t)=\sum_{\tau=t-n}^{t+n} f(\tau) w(t-\tau)\nonumber$$

ニューラルネットワークの場合,
$t$は入力層にあるユニットのインデックスと考えることができる.
関数$w()$はカーネルまたはフィルタと呼ばれる.
畳み込み演算は疎結合のグラフとして表すことができる. 畳み込み層は,
カーネルを入力層上でスライドさせ,
それに対応する出力を計算すると解釈することができる. に,
畳み込み演算を構成する層の例を示す.

<figure id="fig:fig3_6">
<img src="chapters/chap3/fig/fig3_6.png" />
<figcaption>畳み込み層の例</figcaption>
</figure>

::: eg
は, 入力と出力が同じ大きさの畳み込み層である.
出力層の大きさを維持するために,
入力層には値0のユニットが2つ追加されている（破線の円）.
畳み込み演算のカーネルは図の右側に示されている. 簡単のため,
非線形活性化関数は図に示していない. この例では, $n = 1$ であり,
カーネル関数は近傍の 3 箇所でのみ定義されている.
:::

実際の機械学習では, 画像のような2次元以上のデータを扱うことが多い.
畳み込み演算は高次元のデータにも拡張可能である. 例えば,
2次元の画像$I$に対して,
2次元のカーネル$K$を用いて以下のように畳み込み演算を行うことができる：
$$S(i,  j)=(I * K)(i,  j)=\sum_{\tau=i-n}^{i+n} \sum_{j=\gamma-n}^{\gamma+n} I(\tau,  \gamma) K(i-\tau,  j-\gamma)\nonumber$$

次に, 畳み込み層の主要な特性について述べる.
一次元データに対する畳み込み層を考えたとしても一般性を失わない.
これらの特性は高次元データにも適用可能である. 畳み込み層は主に,
「スパースな接続」, 「パラメータの共有」,
「平行移動に対する同変性」という3つの重要な特性を持っている.

#### スパースな接続 {#スパースな接続 .unnumbered}

<figure id="fig:fig3_7">
<img src="chapters/chap3/fig/fig3_7.png" />
<figcaption>密な接続とスパースな接続</figcaption>
</figure>

従来のニューラルネットワークでは,
入力ユニットと出力ユニットの間の相互作用は行列で記述することができる.
この行列の各要素は,
各入力ユニットと各出力ユニット間の相互作用を記述する独立なパラメータである.
しかし, 畳み込み層においては層間の接続は疎になることが多い. は,
従来のニューラルネットワーク層と畳み込みニューラルネットワーク層の比較を示している.
この図では, 1つの出力ユニット$S_3$と,
$S_3$に影響を与える対応する入力ユニットを強調して表示している. 明らかに,
左の密な結合の場合には,
1つの出力ユニットがすべての入力ユニットの影響を受けている. しかし,
右の畳み込みニューラルネットワーク層では,
出力ユニット$S_3$は3つの入力ユニット$x_2$, $x_3$,
$x_4$（$S_3$の「受容野」と呼ばれる）の影響を受けるだけである.
スパースな接続の大きな利点は,
計算効率を大きく向上させることができる点である.
従来のニューラルネットワークの層では,
$N$個の入力ユニットと$M$個の出力ユニットがあるとき,
$N\times M$個のパラメータが存在し,
この層の1回の計算量は$O(N\times M)$である. 一方で,
同じ数の入力と出力ユニットを持つ畳み込み層は,
カーネルサイズが$K$であるとき, $K\times M$個のパラメータしか持たず,
計算量は$O(K\times M)$にまで減少する. なお,
ここでは「パラメータの共有」は考慮しない（次で議論する）. つまり,
畳み込みニューラルネットワークの計算は,
従来のニューラルネットワークの計算よりはるかに効率的になる.

#### パラメータの共有 {#パラメータの共有 .unnumbered}

前述したように, 畳み込み層には $K \times M$ 個のパラメータが存在する.
しかし, 畳み込み層の「パラメータの共有」により,
この数はさらに減少させることができる. 「パラメータの共有」とは,
異なる出力ユニットに対して計算を行う際に,
同じパラメータセットを共有することである. 畳み込み層では,
すべての出力ユニットの値を計算するために同じカーネルが使用される.
このため, 当然ながらパラメータは共有されることになる. はその例であり,
同じ色の接続は同じパラメータを共有する. この例では,
カーネルサイズを3としているため, 3つのパラメータが存在することになる.
一般に, カーネルサイズが$K$の畳み込み層では, パラメータは$K$個になる.
従来のニューラルネットワーク層の$N \times M$個のパラメータと比較すると,
$K$個というパラメータ数はかなり小さく,
結果として必要なメモリもはるかに抑えられる.

<figure id="fig:fig3_8">
<img src="chapters/chap3/fig/fig3_8.png" />
<figcaption>パラメータの共有</figcaption>
</figure>

#### 平行移動に対する同変性 {#平行移動に対する同変性 .unnumbered}

パラメータを共有する仕組みからは,
CNNのもう一つの重要な特性である「平行移動に対する同変性」が導かれる.
ある関数が入力の変化と同じように出力が変化する場合,
その関数は同変であるという. 具体的には, 関数 $f ()$ は,
$f (g(x)) = g( f (x))$ のとき, 関数 $g()$ に対して同変である.
畳み込み演算の場合, 平行移動に対して同変であることは容易に確かめられる.
例えば, の入力ユニットを1ユニット右にシフトしたとしても,
出力は同じように1ユニット右にシフトした結果となる. この性質は,
ある特徴がどこに現れるかよりも,
それが現れるかどうかを重視するようなタスクにおいて重要となる. 例えば,
ある画像に猫が写っているかどうかを認識する場合,
画像中のどこに特徴があるかではなく,
猫が写っていることを示す重要な特徴があるかどうかが問題となる.
CNNのこのような平行移動に対する同変性という特性は,
画像分類の分野で成功するために極めて重要である（Krizhevsky et al.2012;
He et al.2016)．

### 実際の畳み込み層

実際には, CNNにおける畳み込みについて議論するとき,
数学的に定義されているような厳密な畳み込み演算を考えることはない.
実際に使われる畳み込み層は数学的な定義とは若干異なる.
入力は実数値だけではなく, ベクトル値である場合が多い. 例えば,
$N \times N$画素からなるカラー画像では, 各画素に赤, 緑,
青それぞれの強度を表す3つの値が割り当てられている.
各色は入力画像の「チャンネル」を表す.
一般に，入力画像のi番目のチャンネルは,
全ての入力ベクトルのi番目の要素で構成される.
各位置（例えば画像の場合は画素）におけるベクトルの長さがチャンネル数となる.
したがって, 畳み込みは通常3次元で行われるが,
そのうち2次元では「スライドする」だけである（つまり,
チャンネル方向の次元には畳み込みは行われない=「スライドしない」）.
さらに, 典型的な畳み込み層では, 入力層から特徴を抽出するために,
複数の異なるカーネルが並列に適用される. その結果,
出力層も複数チャンネル存在することになる.
ここでは各カーネルの結果が各出力チャンネルに対応することになる.
$L$個のチャンネルを持つ入力画像$I$を考えてみよう.
$P$個のカーネルを用いた畳み込み演算は次のように定式化することができる：
$$S(i, j, p)=\left(I * K_{p}\right)(i, j)=\sum_{l=1}^{L} \sum_{\tau=i-n}^{i+n} \sum_{j=\gamma-n}^{\gamma+n} I(\tau, \gamma, l) K_{p}(i-\tau, j-\gamma, l), p=1, \ldots P
    \label{eq:3_2}$$
ここで$K_p$は$p$番目のカーネルで、$(2n+1)^2\cdot L$個のパラメータを持つ。
出力は$P$チャンネルから成る。

多くの場合, 計算量をさらに減らすため,
入力上でカーネルをスライドさせるときに,
いくつかの位置を規則的にスキップすることができる.
この畳込みは$s$番目ごとに行われ, $s$を通常「ストライド」と呼び,
このようなストライドを持つ畳み込みをストライド付き畳み込みと呼ぶ.
例（ストライド$s$が2の場合）を(a)に図示した. ストライド付き畳み込みは,
(b)に図示したように,
通常の畳み込みの結果をダウンサンプリングしたものと見なすこともできる.
ストライド $s$
のストライド付き畳み込みは，次のように表現することができる：
$$\begin{array}{l}S(i, j, p)= \\ \sum_{l=1}^{L} \sum_{\tau=i-n}^{i+n} \sum_{j=\gamma-n}^{\gamma+n} I(\tau, \gamma, l) K_{p}((i-1) \cdot s+1-\tau,(j-1) \cdot s+1-\gamma, l)\end{array}\nonumber$$

<figure id="fig:fig3_9">
<img src="chapters/chap3/fig/fig3_9.png" />
<figcaption>ストライド付き畳み込みの概念図</figcaption>
</figure>

ストライドを $s = 1$
とすると，[\[eq:3_2\]](#eq:3_2){reference-type="eqref"
reference="eq:3_2"}のようにストライドなし畳み込みと等価になる．
前述したように, 通常は出力の大きさを維持するために,
入力にゼロパディングが施される. パディングの大きさ,
受容野の大きさ（またはカーネルの大きさ）, そしてストライドによって,
（入力サイズが固定である場合の）出力サイズが決定される. 具体的には,
サイズ$N$の1次元入力を考え, パディングのサイズを$Q$,
受容野のサイズを$F$,
ストライドのサイズを$s$とすると、出力のサイズ$O$は以下の式で計算することができる：
$$O=\frac{N-F+2 Q}{s}+1
    \label{eq:3_3}$$

::: eg
のストライド付き畳み込みの入力サイズは$N=5$である。
カーネルサイズは$F=3$で, ゼロパディングは$Q=1$である.
ストライドが$s=2$であることから,
[\[eq:3_3\]](#eq:3_3){reference-type="eqref"
reference="eq:3_3"}を用いて出力サイズは次のように計算される：
$$O=\frac{N-F+2 Q}{s}+1=\frac{5-3+2 \times 1}{2}+1=3\nonumber$$
:::

### 検出層

順伝搬型ネットワークと同様に,
畳み込み演算の後に非線形活性化関数が適用される.
CNNで広く用いられている活性化関数はReLU関数である.
非線形活性化を適用するプロセスは, 検出ステージまたは検出層とも呼ばれる.

### プーリング層

畳み込み層と検出層の後に, 通常はプーリング層が続く. プーリング関数は,
近くの統計量をまとめて出力する. 従って, プーリング層の後では,
データの幅と高さが小さくなる. しかし,
データの深さ（チャンネル数）は変化しない.
一般的に使用されるプーリングには. に示すように,
最大値プーリングと平均値プーリングがある.
これらのプーリング演算は$2\times2$の局所近傍を入力とし,
それらに基づいて1つの値を出力する. その名前が示すように,
最大値プーリングは局所近傍の最大値を出力とし,
平均値プーリングは局所近傍の平均値を出力とする.

<figure id="fig:fig3_10">
<img src="chapters/chap3/fig/fig3_10.png" />
<figcaption>CNNにおけるプーリング</figcaption>
</figure>

### CNNフレームワークの全体像 {#sec:3_3_5}

畳み込み演算とプーリング演算を説明したので,
次に分類問題に対する畳み込みニューラルネットワークの全体的な枠組みについて述べる.
に示すように, 分類のための全体的な枠組みは, 特徴抽出パートと分類パートの
2 つに大別される. 特徴抽出パートは, 畳み込み層とプーリング層からなり,
入力から特徴を抽出する. 一方で,
分類パートは全結合の順伝播型ニューラルネットワークで構成されている.
これら2つの要素をつなぐのが平坦化処理である.
特徴抽出パートで抽出された複数チャネルの特徴量行列を1つの特徴量ベクトルに平坦化し,
分類パートの入力とする. では, 1 つの畳み込み層と 1
つのプーリング層しか描かれていないが,
実際には複数の畳み込み層とプーリング層を重ねるのが一般的である. 同様に,
分類パートにおいても順伝播型ニューラルネットワークは複数の全結合層で構成される場合がある.

<figure id="fig:fig3_11">
<img src="chapters/chap3/fig/fig3_11.png" />
<figcaption>CNNにおけるプーリング</figcaption>
</figure>

## リカレントニューラルネットワーク {#sec:3_4}

音声認識, 機械翻訳, センチメント分類などの多くのタスクにおいて,
系列データを扱う必要がある. 機械翻訳は,
ある言語の文（単語の列）が与えられたときに,
それを別の言語に翻訳することを目的とする. したがって,
入力と出力の両方が系列データである. センチメント分類は,
与えられた文や文書のセンチメントを予測するもので, 入力は系列データで,
出力はセンチメントの分類を示す値である. こうしたタスクのために,
系列データの各要素を入力層の入力ユニットと見なし,
標準的なニューラルネットワークモデルを使えばよいと考えるかもしれない.
しかし, この戦略は2つの主な理由により,
系列データに対してはうまくいかない. まず,
標準的なネットワークモデルでは,
入力と出力のサイズが固定されていることが多いが,
系列データの入力や出力はサンプルによって異なる長さを持つことがある.
次に, より重要なこととして, 標準的なネットワークモデルでは,
系列の異なる位置からの入力を扱うためのパラメータが共有されていない.
例えば, 言語関連のタスクでは, \"I went to the Yellow Stone National park
last summer\" と \"Last summer, I went to the Yellow Stone National
park\" という2つの文が与えられたとする. 学習モデルは,
両方の文において時期は\"last summer\"であると解釈してほしいが, \"last
summer\"という情報はそれぞれの文で異なる位置に現れる.
これを扱う自然な方法は, CNNと同様にパラメータを共有することである.
以上の2つの課題を解決するために登場したのが, RNN（Recurrent Neural
Network）である. RNNは, 系列の各要素に同じ関数を再帰的に適用する.
系列のすべての位置が同じ関数で処理されるため,
異なる位置間でのパラメータの共有が自然に実現される. 一方で,
系列の長さに関係なく同じ関数を繰り返し適用できるため,
長さの異なる配列を本質的に扱うことができる.

### 伝統的なRNNの構成

長さ$n$の系列は,
（$\mathbf{x^{(1)}},\mathbf{x^{(2)}},...,\mathbf{x^{(n)}}$）と表すことができる.
に示すように, 従来のRNNモデルでは, 系列の要素を1つずつ取り込み,
ニューラルネットワークのブロックで処理していた.
ニューラルネットワークのブロックは,
系列の要素だけでなく前のブロックから流れてきた情報も入力として受け取ることが多い.
その結果、系列の初期位置の情報が系列全体に流れることができる.
各ニューラルネットワークのブロックは同一である. なお,
のRNNモデルは各位置$i$に出力$\mathbf{y^{(i)}}$を持つが,
これはRNNモデルには必須ではない.

ニューラルネットワークのブロックは, 2つの入力と2つの出力をもつ.
出力を$\mathbf{y^{(i)}}$,
次の位置に流れる情報を$\mathbf{h^{(i)}}$とする.
$\mathbf{h^{(0)}}$`<!-- -->`{=html}0で初期化されることが多い.
$i$番目の要素を処理する手順は, 次のように定式化できる：
$$\begin{array}{l}\mathbf{h}^{(i)}=\alpha_{h}\left(\mathbf{W}_{h h} \cdot \mathbf{h}^{(i-1)}+\mathbf{W}_{h x} \mathbf{x}^{(i-1)}+\mathbf{b}_{h}\right) \nonumber \\ \mathbf{y}^{(i)}=\alpha_{y}\left(\mathbf{W}_{y h} \mathbf{h}^{(i)}+\mathbf{b}_{y}\right)\end{array}\nonumber$$
ここで、$\mathbf{W}_{h h},\mathbf{W}_{h x}, \mathbf{W}_{y h}$は線形変換をする行列で,
$\mathbf{b}_{h}, \mathbf{b}_{y}$はバイアス項,
$\alpha_{h}, \alpha_{y}$は活性化関数を表す.

系列データを扱う場合,
系列の長期的な依存関係を捉えることが非常に重要となる. 例えば,
言語モデルでは文中で遠くに現れる2つの単語が密接に関連していることがある.
しかし,
従来のRNNモデルは長期的な依存関係を捉えるのが苦手であることが分かっている.
一番の問題は,
多くのネットワークのブロックにわたって勾配が消滅するか爆発しがちであるということだ.
この2つの現象は, 学習のプロセスで問題を引き起こす.
勾配爆発は最適化に影響を及ぼし,
勾配消失は後の位置の情報が前の位置の計算に伝わりづらくなってしまう.
これらの問題を解決するため, ゲート付きRNNモデルが提案されている.
代表的なゲート付きRNNモデルとして, LSTM (Long short-term memory)
(Hochreiter and Schmidhuber, 1997) とGRU (gated recurrent unit) (Cho et
al., 2014a) がある.

<figure id="fig:fig3_12">
<img src="chapters/chap3/fig/fig3_12.png" />
<figcaption>伝統的なRNNの構成</figcaption>
</figure>

### LSTM {#sec:3_4_2}

LSTMの全体的な構造は従来のRNNモデルと同じである. また,
系列の要素に同一のニューラルネットワークを適用するチェーン構造も持っている.
重要な違いは, LSTMの情報の流れを制御するため,
ゲート・ユニットが導入されている点である. に示すように,
系列内の連続した位置を流れる情報にはセル状態$\mathbf{C}^{(t-1)}$と隠れ状態$\mathbf{h}^{(t-1)}$が含まれている.
セル状態は前の状態から次の状態へ情報を伝達し,
隠れ状態はどのようにして情報を伝達するのかを決める.
セル状態$\mathbf{h}^{(t)}$は,
必要に応じて（例えば入力も出力も系列であるようなタスクなどで）この位置の出力としても機能する.

<figure id="fig:fig3_13">
<img src="chapters/chap3/fig/fig3_13.png" />
<figcaption>LSTMの構成ブロック</figcaption>
</figure>

LSTMではまず最初のステップで,
前のセルから来た情報のうち何を捨てるかを決める.
この決定は「忘却ゲート」で行われる.
忘却ゲートでは前の隠れ状態$\mathbf{h}^{(t-1)}$と新しい入力$\mathbf{x}^{(t)}$をもとにして,0から1の値を出力し,
セル状態$\mathbf{C}^{(t-1)}$に渡される. 各要素の0から1の値は,
どの程度の情報を捨てるかを表す. 出力は,
セル状態$\mathbf{C}^{(t-1)}$と同じ次元をもつベクトル$\mathbf{f}_t$に集約される.
具体的には, 忘却ゲートは以下のように定式化される：
$$\mathbf{f}_{t}=\sigma\left(\mathbf{W}_{f} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{f} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{f}\right)\nonumber$$
ここで, $\mathbf{W}_f$と$\mathbf{U}_f$はパラメータで,
$\mathbf{b}_f$はバイアス項,
$\sigma()$はシグモイド関数で入力を0から1に変換する.

次のステップで,
入力$\mathbf{x}^{(t)}$のうち新しいセル状態に何を保存するかを決める.
この決定は「忘却ゲート」と同様に, 「入力ゲート」で行われる.
入力ゲートは以下のように定式化される：
$$\mathbf{i}_{t}=\sigma\left(\mathbf{W}_{i} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{i} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{i}\right)\nonumber$$
入力$\mathbf{x}^{(t)}$を数層のニューラルネットワークで処理することで候補セル$\tilde{\mathbf{C}}^{(t)}$を生成し,
これを使ってセル状態を更新する. このプロセスは次のように書ける：
$$\tilde{\mathbf{C}}^{(t)}=\tanh \left(\mathbf{W}_{c} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{c} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{c}\right)\nonumber$$
その後,
古いセル状態$\mathbf{C}^{(t-1)}$と新しい候補セル$\tilde{\mathbf{C}}^{(t)}$を用いて,
新しいセル状態$\mathbf{C}^{(t)}$を生成する：
$$\mathbf{C}^{(t)}=\mathbf{f}_{t} \odot \mathbf{C}^{(t-1)}+\mathbf{i}_{t} \odot \tilde{\mathbf{C}}^{(t)}\nonumber$$
ここで, $\odot$という記号はアダマール積（成分ごとに積をとる）を表す.

最後のステップで, 隠れ状態$\mathbf{h}^{(t)}$を生成し,
これが次のブロックに流れていく.
また、場合によってはこれがこのブロックでの出力となる.
この隠れ状態は更新されたセル状態$\mathbf{C}^{(t)}$に基づいており,
「出力ゲート」がセル状態のどの部分を保存するかを決定する.
出力ゲートは忘却ゲートと入力ゲートと同じように次のように定式化される：
$$\mathbf{o}_{t}=\sigma\left(\mathbf{W}_{o} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{o} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{o}\right)\nonumber$$
新しい隠れ状態$\mathbf{h}^{(t)}$は次のように生成される：
$$\mathbf{h}^{(t)}=\mathbf{o}_{t} \odot \tanh \left(\mathbf{C}^{(t)}\right)\nonumber$$

LSTMの全体のプロセスは次のようにまとめることができる： $$\begin{split}
    \begin{array}
    {l}\mathbf{f}_{t}=\sigma\left(\mathbf{W}_{f} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{f} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{f}\right) \\ \mathbf{i}_{t}=\sigma\left(\mathbf{W}_{i} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{i} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{i}\right) \\ \mathbf{o}_{t}=\sigma\left(\mathbf{W}_{o} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{o} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{o}\right) \\ \tilde{\mathbf{C}}^{(t)}=\tanh \left(\mathbf{W}_{c} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{c} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{c}\right) \\ \mathbf{C}^{(t)}=\mathbf{f}_{t} \odot \mathbf{C}^{(t-1)}+\mathbf{i}_{t} \odot \tilde{\mathbf{C}}^{(t)} \\ \mathbf{h}^{(t)}=\mathbf{o}_{t} \odot \tanh \left(\mathbf{C}^{(t)}\right)
    \end{array}
    \end{split}
    \label{eq:3_4}$$

便宜上, で表される,
i番目の位置のLSTMのニューラルネットワークを次のように書く：

$$\mathbf{C}^{(t)}, \mathbf{h}^{(t)}=\operatorname{LSTM}\left(\mathbf{x}^{(t)}, \mathbf{C}^{(t-1)}, \mathbf{h}^{(t-1)}\right)
    \label{eq:3_5}$$

### GRU

のGRU（Gated recurrent unit）は, LSTMを変形した構造をしており,
LSTMの忘却ゲートと入力ゲートを「更新ゲート」として統合し,
セル状態と隠れ状態を同じものとして統合したものと見なすことができる.
これらの変更により,
よりシンプルなゲート付きRNNモデルを構成することができる.
GRUは以下のように定式化される： $$\begin{split}
        \begin{array}{l}\mathbf{z}_{t}=\sigma\left(\mathbf{W}_{z} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{z} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{z}\right) \\ \mathbf{r}_{t}=\sigma\left(\mathbf{W}_{r} \cdot \mathbf{x}^{(t)}+\mathbf{U}_{r} \cdot \mathbf{h}^{(t-1)}+\mathbf{b}_{r}\right) \\ \tilde{\mathbf{h}}^{(t)}=\tanh \left(\mathbf{W} \cdot \mathbf{x}^{(t)}+\mathbf{U} \cdot\left(\mathbf{r}_{t} \odot \mathbf{h}^{(t-1)}\right)+\mathbf{b}\right) \\ \mathbf{h}^{(t)}=\left(\mathbf{1}-\mathbf{z}_{t}\right) \odot \tilde{\mathbf{h}}^{(t)}+\mathbf{z}_{t} \odot \mathbf{h}^{(t-1)}\end{array}
        \label{eq:3_6}
    \end{split}$$ ここで, $\mathbf{z}_t$は更新ゲートであり,
$\mathbf{r}_t$はリセットゲートである. 便宜上,
こののプロセスを次のようにまとめる：
$$\mathbf{h}^{(t)}=\operatorname{GRU}\left(\mathbf{x}^{(t)}, \mathbf{h}^{(t-1)}\right)$$

<figure id="fig:fig3_14">
<img src="chapters/chap3/fig/fig3_14.png" />
<figcaption>GRUの構成ブロック</figcaption>
</figure>

## オートエンコーダー {#sec:3_5}

<figure id="fig:fig3_15">
<img src="chapters/chap3/fig/fig3_15.png" />
<figcaption>オートエンコーダーは, 入力から出力までを記憶する.
太字の接続は入力から出力まで記憶することを示し,
他の接続はオートエンコーダでは使用しない（重み0）ことを示す.</figcaption>
</figure>

オートエンコーダーは,
入力を再現して出力しようとするニューラルネットワークと見なすことができる.
具体的には, 入力情報をエンコードした中間隠れ表現$\mathbf{h}$を持つ.
オートエンコーダーは2つの要素から構成される： 1) 入力
$\mathbf{x}$を符号化して符号化表現$\mathbf{h}$を生成する, エンコーダ部分
$\mathbf{h} = f (x)$ と, 2) 符号化表現 $\mathbf{h}$ から $\mathbf{x}$
を復元するデコーダ部分$\hat{\mathbf{x}} = g (h)$である.
もしオートエンコーダが入力を完全に再現することができるなら,それは使い物にならない.
むしろ, オートエンコーダーはいくつかの制限を入れた上で,
入力を近似的に再現するものである. より具体的には,
オートエンコーダは入力の必要な情報を符号化表現 $\mathbf{h}$ に圧縮して,
満足のいく出力を再現する. オートエンコーダの一般的な構成をに示す.
入力$\mathbf{x}$は「ボトルネック」を通過し,
ここでは符号化表現$\mathbf{h}$に保存できる情報が制御される. そして,
デコーダ部分$\mathbf{h}$を利用して入力$\mathbf{x}$を再構成した$\hat{\mathbf{x}}$を出力する.
オートエンコーダーのネットワークは次の再構成誤差を最小化することで学習させることができる：
$$\ell(\mathbf{x}, \hat{\mathbf{x}})=\ell(\mathbf{x}, g(f(\mathbf{x})))$$
ここで,
$\ell(\mathbf{x}, \hat{\mathbf{x}})$は$\mathbf{x}$と$\hat{\mathbf{x}}$の違いを表す.

<figure id="fig:fig3_16">
<img src="chapters/chap3/fig/fig3_16.png" />
<figcaption>オートエンコーダーの一般的な構成</figcaption>
</figure>

例えば, 平均二乗誤差を$l$とすることができる. オートエンコーダーでは,
「ボトルネック」の設計が重要である. に示すように,
「ボトルネック」がないと,
オートエンコーダは単に入力を記憶してデコーダにそのまま渡して入力を再現することを学習してしまい,
オートエンコーダーが使い物にならなくなる可能性がある.
「ボトルネック」を設計する（すなわち,
オートエンコーダーに制約を加える）方法はさまざまある. 自然な方法は,
符号化表現$\mathbf{h}$の次元数を制限することであり,
これは不完全オートエンコーダーの考え方につながる. また,
正則化項を追加して入力と出力間の記憶を抑止することもでき,
これは正則化オートエンコーダーの考え方につながる.

### 不完全オートエンコーダー

符号化表現$\mathbf{h}$の次元数が入力$\mathbf{x}$より小さくなるように制限することは,
「ボトルネック」を設計する上で, 簡単で自然な方法である.
入力次元より小さい符号化部分の次元を持つオートエンコーダーは,
「不完全」オートエンコーダーと呼ばれる.
不完全オートエンコーダーの例はに示されている.
エンコーダーとデコーダーはともに1層のネットワークしか持たず,
隠れ層は入力層より少ないユニットしか持っていない.
このモデルは再構成誤差を最小にすることで,
入力の最も重要な特徴を隠れ符号化表現に保存することができる.

### 正則化オートエンコーダー

また, エンコーダーとデコーダーの層を重ねることで,
オートエンコーダーをより深くすることができる.
深いオートエンコーダーの場合, その表現力の大きさに注意する必要がある.
オートエンコーダーは, エンコーダーとデコーダーの表現力が大きすぎると,
意味があることを何も学べなくなってしまう可能性がある.
オートエンコーダーが単に「恒等関数」を学習してしまうことを防ぐため,
オートエンコーダーの損失関数に正則化項を以下のように入れることができる：

$$\ell(\mathbf{x}, g(f(\mathbf{x})))+\eta \cdot \Omega(\mathbf{h})$$
ここで, $\Omega(\mathbf{h})$は正則化項で,
$\eta$は正則化項の大きさを制御するハイパーパラメータである.

(Olshausen and Field, 1997)の研究では,
符号化表現$\mathbf{h}$の$L_1$ノルムが正則化項として次のように導入されていた：
$$\Omega(\mathbf{h})=\|\mathbf{h}\|_{1}$$
$L_1$ノルム正則化項によって$\mathbf{h}$はスパースになるよう誘導される.
こうしたオートエンコーダーは「スパースオートエンコーダー」とも呼ばれる.

符号化表現をスパースにする別の方法は,$\mathbf{h}$のニューロンがほとんどの時間で不活性であるように制約することである.
ここでいう「不活性」とは,
$\mathbf{h}$のニューロンの値が低いレベルであることを意味する.
ここまでは$\mathbf{h}$を使って隠れ符号化状態を表現しているが,
これではどのような入力がこのコードにつながるのかが明示的にわからない.
そこで, 関係を明示的に表現するため, 与えられた入力$\mathbf{x}$に対して,
オートエンコーダーで学習したその符号化表現を$\mathbf{h}(x)$とする.
サンプル集合$\left\{\mathbf{X}_{(i)}\right\}_{i=1}^{m}$の符号化表現の平均は次のように書くことができる：
$$\overline{\mathbf{h}}=\frac{1}{m} \sum_{i=1}^{m} \mathbf{h}\left(\mathbf{x}_{(i)}\right)$$

次に, 隠れ符号化表現の各要素が小さな値$\rho$に近づくようにしたい.
例えば, $\rho$を0.05とする. (Ng et al., n.d.)の研究では,
隠れ表現の各要素を̄$\overline{\mathbf{h}}$を平均とするベルヌーイ確率変数として扱っている.
KLダイバージェンスを用いることで,
この確率変数が$\rho$を平均とするベルヌーイ確率変数と近づくように制約することができる：
$$\Omega(\mathbf{h})=\sum_{j}\left(\rho \log \frac{\rho}{\overline{\mathbf{h}}[j]}+(1-\rho) \log \frac{1-\rho}{1-\overline{\mathbf{h}}[j]}\right)
    \label{eq:3_12}$$

の正則化項を持つオートエンコーダーも「スパースオートエンコーダー」と呼ばれる.
正則化項は, 「不完全オートエンコーダー」に適用することもできるが,
正則化項単体で「ボトルネック」の役割を果たすこともできる.
正則化項を用いれば,
隠れ符号化表現$\mathbf{h}$は必ずしも入力より小さい次元である必要はなくなる.

## 深層ニューラルネットワークの学習

この節では, 深層ニューラルネットワークの学習手順について説明する. まず,
ニューラルネットワークを学習するための一般的なアプローチである,
勾配降下法とその変形版について簡単に紹介する. 次に,
ニューラルネットワークのパラメータの勾配を計算するための効率的な動的アルゴリズムである,
逆伝播法について説明する.

### 勾配降下法

深層モデルを学習させるためには,
学習させたいパラメータに関する損失関数$\mathcal{L}$を最小化する必要がある.
一般に, $\mathbf{W}$を最適化するすべてのパラメータとして,
損失関数を$\mathcal{L}(\mathbf{W})$と表す.
深層学習における損失関数の最小化には,
勾配降下法とその変形版がよく用いられる. 勾配降下法（Cauchy, n.d.）は,
一次の繰り返し最適化アルゴリズムである. 各繰り返しにおいて,
以下のように負の勾配の方向へ一歩ずつ, パラメータ$\mathbf{W}$を更新する：
$$\mathbf{W}^{\prime}=\mathbf{W}-\eta \cdot \nabla_{\mathbf{W}} \mathcal{L}(\mathbf{W})$$
ここで,$\nabla_{\mathbf{W}} \mathcal{L}(\mathbf{W})$は勾配を表し,
$\eta$は学習率を表す. 学習率は正の値で,
どの程度$\mathbf{W}$を更新するかを表す. 深層学習では,
学習率$\eta$は小さい定数に固定されることが多い.

損失関数は通常, 学習サンプルのペナルティの総和である.
したがって，損失関数を以下のように書くことができる：
$$\mathcal{L}(\mathbf{W})=\sum_{i=1}^{N_{s}} \mathcal{L}_{i}(\mathbf{W})$$
ここで, $\mathcal{L}_{i}(\mathbf{W})$はi番目のサンプルの損失を表し,
$N_s$はサンプル数を表す. 多くの場合,
直接$\nabla_{\mathbf{W}} \mathcal{L}(\mathbf{W})$を計算するのは非常に手間がかかる.
そこで, 深層ニューラルネットワークの学習で非常によく使われている,
ミニバッチ勾配降下法が登場する. ミニバッチ勾配降下法では,
すべての学習サンプルに対して勾配を評価するのではなく,
学習データから少量のサンプルを抽出し, それを使って勾配を推定する.
この推定された勾配を利用してパラメータを更新する. 具体的には,
勾配は$\sum_{j \in \mathcal{M}} \nabla_{\mathbf{W}} \mathcal{L}_{j}(\mathbf{W})$として推定さる.
ここで,$\mathcal{M}$はミニバッチのサンプル集合を表す. Adagrad (Duchi et
al., 2011), Adadelta (Zeiler, 2012), および Adam (Kingma and Ba, 2014)
などの深層ニューラルネットワークの学習のため,
勾配降下法の変形版も開発されている. これらは一般的に,
標準的な勾配降下法よりも収束性が高い.

### 逆伝播法

<figure id="fig:fig3_17">
<img src="chapters/chap3/fig/fig3_17.png" />
<figcaption>隣り合う層のニューロン</figcaption>
</figure>

勾配に基づく最適化を行うための重要なステップの1つは,
すべてのパラメータに関する勾配を計算することである.
逆伝播法は動的計画法を用いて勾配を計算する効率的な方法である.
逆伝播法は2つの段階からなる： １段階目は「順伝搬」である. この段階では,
入力はモデルの深い層まで通過する.
出力は現在のパラメータセットに対して計算され,損失関数の値が評価される.
2段階目は「逆伝播」である. この段階の目的は,
パラメータに対する損失関数の勾配を計算することである.
チェーン・ルールによれば, すべてのパラメータに対する勾配は,
出力層から後ろ向きに動的に計算することができる. 次に,
逆伝播パスについて説明する.

はそれぞれ異なる層のつながっているニューラルネットワークのユニット$h^{0}, h^{1}, \ldots, h^{k}, o$を表す.
ここで, $h^i$は$i$番目の層のユニットを表し, $h^0$は入力層のユニット,
$o$は出力層のユニットを表す.
$\left(h^{r-1}, h^{r}\right)$の間に1本しかエッジがないとすると,
損失関数の微分はチェーン・ルールを使って次のように書くことができる：
$$\frac{\partial \mathcal{L}}{\partial w_{\left(h^{r-1}, h^{r}\right)}}=\frac{\partial \mathcal{L}}{\partial o} \cdot\left[\frac{\partial o}{\partial h^{k}} \prod_{i=r}^{k-1} \frac{\partial h^{i+1}}{\partial h^{i}}\right] \cdot \frac{\partial h^{r}}{\partial w_{\left(h^{r-1}, h_{r}\right)}} \forall r \in 1 \ldots k
    \label{eq:3_16}$$
ここで,$w_{\left(h^{r-1}, h^{r}\right)}$はユニット$h^{r-1}$と$h^r$の間のパラメータを表す.

複数層のニューラルネットワークでは,
$\left(h^{r-1}, h^{r}\right)$の間に複数パスある場合が多い. したがって,
上の計算で得られた勾配を合計する必要がある：
$$\frac{\partial \mathcal{L}}{\partial w\left(h^{r-1}, h^{r}\right)}=\underbrace{\frac{\partial \mathcal{L}}{\partial o} \cdot\left[\sum_{\left[h^{r}, h^{r+1}, \ldots, h^{k}, o\right] \in \mathcal{P}} \frac{\partial o}{\partial h^{k}} \prod_{i=r}^{k-1} \frac{\partial h^{i+1}}{\partial h^{i}}\right]}_{\text {Backpropagation computes } \Delta\left(h^{r}, o\right)=\frac{\partial \mathcal{L}}{\partial h^{r}}} \frac{\partial h^{r}}{\partial w_{\left(h^{r-1}, h^{r}\right)}}$$
ここで, $\mathcal{P}$は$h^r$から$o$に至るパスの集合を表し,
これは$\left(h^{r-1}, h^{r}\right)$まで拡張することができる.
の右辺は2つの要素があり,
後者は計算が面倒（後述）なのに対し、最初の部分（$\Delta\left(h^{r}, o\right)=\frac{\partial \mathcal{L}}{\partial h^{r}}$と式中に記載）は再帰的に計算が可能である.
次に, 第一項を再帰的に評価する方法について説明する.
第一項は以下のように計算することができる： $$\begin{aligned} 
    \Delta\left(h^{r}, o\right) &=\frac{\partial \mathcal{L}}{\partial o} \cdot\left[\sum_{\left[h^{r}, h^{r+1}, \ldots, h^{k}, o\right] \in \mathcal{P}} \frac{\partial o}{\partial h^{k}} \prod_{i=r}^{k-1} \frac{\partial h^{i+1}}{\partial h^{i}}\right] \\ &=\frac{\partial \mathcal{L}}{\partial o} \cdot\left[\sum_{\left[h^{r}, h^{r+1}, \ldots, h^{k}, o\right] \in \mathcal{P}} \frac{\partial o}{\partial h^{k}} \prod_{i=r+1}^{k-1} \frac{\partial h^{i+1}}{\partial h^{i}} \cdot \frac{\partial h^{r+1}}{\partial h^{r}}\right] 
    \end{aligned}
    \label{eq:3_17}$$

<figure id="fig:fig3_18">
<img src="chapters/chap3/fig/fig3_18.png" />
<figcaption>パスの分解</figcaption>
</figure>

に示したように,
$\mathcal{P}$に属する任意のパスは2つのパートにわけることができる：
$\left(h^{r}, h^{r+1}\right)$間のエッジと,
$h^{r+1}$から$o$までの残りのパスである. 次に,
エッジ$\left(h^{r}, h^{r+1}\right)$を用いて$\mathcal{P}$のパスを分類する.
$\left(h^{r}, h^{r+1}\right)$と同じエッジを共有するパスを$\mathcal{P}_{r+1}$と書く.
$\mathcal{P}_{r+1}$の全てのパスは同じ最初のエッジ$\left(h^{r}, h^{r+1}\right)$を共有しているので,
残りのパス(つまり,
$h^{r+1}$から$o$までのパス)を用いて特徴づけることができる（例外は最初のエッジを除く）.
この残りのパスを$\mathcal{P}'_{r+1}$と書くことにすると,
は次のように簡略化することができる：

$$\begin{aligned} \Delta\left(h^{r}, o\right) &=\frac{\partial \mathcal{L}}{\partial o} \cdot\left[\sum_{\left(h^{r}, h^{r+1}\right) \in \mathcal{E}} \frac{\partial h^{r+1}}{\partial h^{r}} \cdot\left[\sum_{\left[h^{r+1}, \ldots, h_{k}, o\right] \in \mathcal{P}_{r+1}^{\prime}} \frac{\partial o}{\partial h_{k}} \prod_{i=r+1}^{k-1} \frac{\partial h^{i+1}}{\partial h^{i}}\right]\right] \\ &=\sum_{\left(h^{r}, h^{r+1}\right) \in \mathcal{E}} \frac{\partial h^{r+1}}{\partial h^{r}} \cdot \frac{\partial \mathcal{L}}{\partial o} \cdot\left[\sum_{\left[h^{r+1}, \ldots, h_{k}, o\right] \in \mathcal{P}_{r+1}^{\prime}} \frac{\partial o}{\partial h_{k}} \prod_{i=r+1}^{k-1} \frac{\partial h^{i+1}}{\partial h^{i}}\right] \\ &=\sum_{\left(h^{r}, h^{r+1}\right) \in \mathcal{E}} \frac{\partial h^{r+1}}{\partial h^{r}} \cdot \Delta\left(h^{r+1}, o\right) \end{aligned}
    \label{eq:3_18}$$ ここで,
$\mathcal{E}$はユニット$h^r$から$(r+1)$番目の層のユニット$h^{r+1}$への,
存在しうる全てのエッジの集合を表す. に図示したように,
$(r+1)$番目の層の全てのユニットは$h^r$につながっているため,
の最初の和に含まれていることになる.
$h^{r+1}$は$h^{r}$よりもあとの層であり,
$\Delta\left(h^{r+1}, o\right)$は逆伝搬の前のプロセスですでに評価されているので,
そのまま使うことができる. あとは,
の評価のためには$\frac{\partial h^{r+1}}{\partial h^{r}}$を評価するだけである.
そのためには活性化関数を考慮にいれる必要がある.
$\alpha^{r+1}$をユニット$h^{r+1}$の活性化関数にいれる直前の値とする.
すなわち, $h^{r+1}=\alpha\left(a^{r+1}\right)$とする.
$\frac{\partial h^{r+1}}{\partial h^{r}}$を評価するために次のようにチェーン・ルールを使う：
$$\frac{\partial h^{r+1}}{\partial h^{r}}=\frac{\partial \alpha\left(a^{r+1}\right)}{\partial h^{r}}=\frac{\partial \alpha\left(a^{r+1}\right)}{\partial a^{r+1}} \cdot \frac{\partial a^{r+1}}{\partial h^{r}}=\alpha^{\prime}\left(a^{r+1}\right) \cdot w_{\left(h^{r}, h^{r+1}\right)}$$
ここで,
$w_{\left(h^{r}, h^{r+1}\right)}$はユニット$h^r$と$h^{r+1}$の間のパラメータである.
これを用いると,
$\Delta\left(h^{r}, o\right)$を次のように書き換えることができる：
$$\Delta\left(h^{r}, o\right)=\sum_{\left(h^{r}, h^{r+1}\right) \in \mathcal{E}} \alpha^{\prime}\left(a^{r+1}\right) \cdot w_{\left(h^{r}, h^{r+1}\right)} \cdot \Delta\left(h^{r+1}, o\right)
    \label{eq:3_20}$$ ここまでが, の前半部分の評価であり,
後半部分については次のように評価することができる：
$$\frac{\partial h^{r}}{\partial w_{\left(h^{r-1}, h^{r}\right)}}=\alpha^{\prime}\left(a^{r}\right) \cdot h^{r-1}
    \label{eq:3_21}$$

以上から, とを用いることで, を再帰的かつ効率的に評価することができる.

### 過学習の抑制

深層ニューラルネットワークは, モデルの表現力が非常に大きいため,
学習データに対して容易に過学習してしまう. この節では,
ニューラルネットワークの過学習を防ぐための実用的なテクニックを紹介する.

#### 重み正則化 {#重み正則化 .unnumbered}

機械学習において, モデルの過学習を防ぐためには,
モデルのパラメータに対する正則化項を損失関数に含めるという手法が一般的である.
正則化項はモデルパラメータを比較的小さくなるように制限することで,
モデルの汎化性能を向上させる. よく用いられている正則化項は,
モデルパラメータの$L_1$ノルムと$L_2$ノルムの2つである.

#### ドロップアウト {#ドロップアウト .unnumbered}

ドロップアウトは, 過学習を防ぐために有効な手法の一つである（Srivastava
et al.2014）. ドロップアウトでは, 学習手順の各バッチにおいて,
ネットワーク内のいくつかのユニットをランダムに無視する.
各ユニットを無視する確率を制御する,
「ドロップアウト率」$p$というハイパーパラメータを用いる. そして,
各反復計算において、確率$p$に従って,
ネットワーク中のどのニューロンを「ドロップ」するかをランダムに決定する.
ネットワーク全体を使うのではなく,
残りの（「ドロップ」されていない）ニューロンとネットワークを用いて,
各反復計算における計算と予測を行う. なお, ドロップアウトは通常,
学習手順でのみ利用される. すなわち,
推論手順では常にネットワーク全体が予測の際に使用される.

#### バッチ正規化 {#バッチ正規化 .unnumbered}

バッチ正規化（Ioffe and Szegedy, 2015）は当初,
内部共変量が変化する問題を解決するために導入されたが,
過学習を緩和させることにも役立つ. バッチ正規化とは,
前の層からの情報を活性化した結果を,
次の層に送る前に正規化することである. 具体的には,
ミニバッチ学習の際にバッチの平均を引き,
バッチの標準偏差を割ることで正規化する. 推論段階では,
母集団の統計量を用いて正規化を行う.

## 本章のまとめ

本章ではまず, 順伝播型ネットワーク, 畳み込みニューラルネットワーク,
リカレントニューラルネットワーク, オートエンコーダーなど,
様々な基本的な深層学習のネットワーク構成を紹介した. 次に,
ネットワークの学習のための勾配降下法と逆伝播法について説明した. 最後に,
これらのネットワークの学習過程における過学習を防止するための実用的なテクニックについて概説した.

## 参考文献

深層学習やニューラルネットワークをより深く理解するためには, 線形代数,
確率, 最適化に関する正しい知識が必要である. これらのテーマについては,
*Linear algebra* (Hoffman and Kunze, n.d.), *An Introduction to
Probability Theory and Its Applications* (Feller, 1957), *Convex
Optimization* (Boyd et al., 2004)や*Linear Algebra and Optimization for
Machine Learning* (Aggarwal, 2018) など, 質の高い書籍が多く存在する.
また, これらのトピックについては, *Pattern Recognition and Machine
Learning*(Bishop, 2006)などの機械学習の本でも簡単に紹介されている. *Deep
Learning* (Goodfellow et al., 2016) や *Neural Networks and Deep
Learning: A Textbook*(Aggarwal, 2018) など,
深層ニューラルネットワークに関するより詳しい知識や内容を扱う専門書も存在する.
また, Tensorflow (Abadi et al., 2015) やPytorch (Paszke et al., 2017)
などのライブラリやプラットフォームで,
様々な深層ニューラルネットワークモデルを簡単に構築することもできる.
