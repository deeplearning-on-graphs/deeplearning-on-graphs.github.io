[メインページ](../../index.markdown)

[章目次](./chap3.md)
## 3.1. はじめに

機械学習は，明示的なプログラミングを介さずに，サンプルデータから適切な動作を学習させることを目的としたコンピュータの研究分野である． そして機械学習の一種である深層学習は，ニューラルネットワークを基盤とした機械学習アルゴリズムである． 実は，深層学習の主要な構成要素のほとんどは数十年前から既に存在していたが，深層学習が普及したのは近年のことである．

ニューラルネットワークのアイデアは，「マカロック・ピッツのニューロンモデル（McCulloch and Pitts, 1943）」が初めて紹介された1940年代に遡る． ここで提案された線形モデルは，入力情報を線形的に集約することで，入力が2つのカテゴリのうちどちらに属するかを判断することができる． その後，パーセプトロンが開発され， これによってサンプルを与えることによるパラメータの学習ができるようになった(Rosenblatt, 1958)．

そこから時を経てニューラルネットワークの研究が再び盛り上がったのは1980年代のことである． この時期の大きなブレークスルーの1つは，誤差逆伝播法を用いた，深層ニューラルネットワークモデルの学習に成功したことである (Rumelhart *et al*., 1986, Le Cun and Fogelman-Soulié, 1987)． なお，誤差逆伝播法という手法自体は既に1960年代から多くの先行研究があり，ニューラルネットワークの学習への応用に初めて言及したのはWerbosである（元論文は彼の著書(Werbos, 1994)に掲載されている）． 誤差逆伝播法は深層学習の時代である現代においても，深層モデルを学習するためのアルゴリズムとして主流となっている．

深層学習の研究は，近年の"ビッグデータ"や強力な計算資源の充実により再び流行し，かつてないほどの注目を集めている． また，高速な"GPU"の登場によって，大規模な深層モデルを学習することが可能になったという点も重要である． その結果，データ量がますます大きくなったとしてもこれらのモデルがうまく一般化できることが保証された． この2つの利点により，様々な研究分野で深層学習が大成功を収め，現実世界に多大な影響を与える結果となった． 様々な応用例において，深層ニューラルネットワークは従来の手法を大差で凌駕している．

いくつか具体例を紹介しよう． 深層学習は，画像認識タスクのパフォーマンスを大幅に向上させた． 「ImageNet Large-Scale Visual Recognition Challenge」は，画像認識における最大のコンテストで，2010年から2017年まで毎年開催された． 2012年には，深層学習を用いた畳み込みニューラルネットワーク（CNN）が，Top-5 Error [^1] を26.1％から15.3％に減らすという大差で，このチャレンジで初めて優勝した（Krizhevsky *et al*., 2012）．


それ以降はCNNが安定して優勝しており，Top-5 Errorをさらに3.57％まで押し下げた（He *et al*., 2016）．

また，深層学習は音声認識システムの性能を飛躍的に向上させている（Dahl *et al*. 2010, Deng *et al*. 2010, Seide *et al*. 2011）． 深層学習技術を音声認識に導入したことで，長年停滞していたエラー率が大きく押し下げた．

自然言語処理(NLP)の研究分野も，深層学習技術によって大きく加速されている． LSTM（Hochreiter and Schmidhuber，1997）などのリカレントニューラルネットワークは，機械翻訳（Sutskever *et al*., 2014; Bahdanau *et al*., 2014）や対話システム（Vinyals and Le，2015）といったSequence-to-Sequence (Seq2Seq)タスクで広く利用されている [^2] ．




"グラフ深層学習"の研究は深層学習に基づいているため，基本的な深層学習の技術を理解することが不可欠である． そこで本章では，順伝搬型ネットワーク，畳み込みネットワーク（CNN），リカレントニューラルネットワーク（RNN），オートエンコーダーなど，グラフ深層学習を研究する上で基礎となる重要な深層学習技術を簡単に紹介する． 本章では基本的な深層モデルに焦点を当てているが，後の章では変分オートエンコーダー（VAE）や敵対的生成ネットワーク（GAN）などのより高度な深層モデルに議論を広げていく．


[メインページ](../../index.markdown)

[章目次](./chap3.md)

[前の節へ](./subsection_00.md) [次の節へ](./subsection_02.md)

[^1]: 訳注：Top-5 Errorは，画像認識タスクの評価指標であり，上位5つの予測候補の中に正解が入っていない確率を示している．
[^2]: 訳注：これ以降NLPの分野は目覚ましく発展しており，セルフ・アテンション機構を導入したTransformer（Vaswani *et al*., 2017）や，Transformerを用いた大規模な事前学習モデルであるGPT（Radford *et al*., 2018）の登場により，幅広いNLPタスクにおいて高い性能を発揮している．
