[メインページ](../../index.markdown)

[章目次](./chap6.md)
## 6.1. はじめに

従来のDNN（深層ニューラルネットワーク）をグラフに一般化したGNN（グラフニューラルネットワーク）は，DNNが持つメリットとデメリットを両方受け継いでいる． DNNと同様に，GNNはノード中心のタスクやグラフ中心のタスクなど，グラフに関連した様々なタスクで効果を発揮している．しかし一方で，従来のDNNは，専用に設計された「敵対的な攻撃(adversarial attacks)」に対して**脆弱**であることが示されている (Goodfellow *et al*., 2014b; Xu *et al*., 2019b)． 敵対的な攻撃は，データサンプルに見つけにくい摂動（微妙な変化）を加えることで，モデルが誤った結果をするように仕向ける． GNNもこのデメリットを受け継いでいることが，次第に明らかになってきている． 敵対者（攻撃者）は，グラフの構造やノードの特徴量を意図的に操作してグラフの敵対的摂動を発生させ．GNNモデルを欺くことができる． こういったGNNの弱点は，金融システムやリスク管理といった安全性が重視されるアプリケーションへの導入に大きな懸念を投げかける結果になる． 例えば，信用評価システムにおいては，詐欺師が高信頼顧客とのつながりを偽装して詐欺師検出モデルを回避したり，また，スパム送信者が簡単に偽のフォロワーを作成してフェイクニュースがレコメンドされ，広く拡散する確率を高めることができてしまう．

以上のことから，グラフに対する敵対的攻撃とその対策に対する研究がますます注目を集めている． 本章では，まずグラフに対する敵対的攻撃の概念と定義を紹介し，どのような敵対的攻撃が存在するかを詳述する． その後，これらの敵対的攻撃に対する代表的な防御技術について議論していく．


[メインページ](../../index.markdown)

[章目次](./chap6.md)

[次の節へ](./subsection_02.md)


