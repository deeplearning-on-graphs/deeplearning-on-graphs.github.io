## 10.1節 はじめに
- Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition [amazon](https://www.amazon.co.jp/dp/0130950696)
- Abstract Meaning Representation for Sembanking [PDF](https://aclanthology.org/W13-2322.pdf)
- Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling [arxiv](https://arxiv.org/abs/1703.04826)
- Question Answering by Reasoning Across Documents with Graph Convolutional Networks [arxiv](https://arxiv.org/abs/1808.09920)
- BAG: Bi-directional Attention Entity Graph Convolutional Network for Multi-hop Reasoning Question Answering [arxiv](https://arxiv.org/abs/1904.04969)
- Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks [arxiv](https://arxiv.org/abs/1809.02040)
- Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs [arxiv](https://arxiv.org/abs/1905.07374)
- Graph Convolution over Pruned Dependency Trees Improves Relation Extraction [arxiv](https://arxiv.org/abs/1809.10185)
- GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction [リンク](https://aclanthology.org/P19-1136/)
- Attention Guided Graph Convolutional Networks for Relation Extraction [arxiv](https://arxiv.org/abs/1906.07510)
- Graph Neural Networks with Generated Parameters for Relation Extraction [リンク](https://aclanthology.org/P19-1128/)
- Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network [arxiv](https://arxiv.org/abs/1906.04684)
- Joint Type Inference on Entities and Relations via Graph Convolutional Networks [リンク](https://aclanthology.org/P19-1131/)
- Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks [arxiv](https://arxiv.org/abs/1903.01306)
- Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks [arxiv](https://arxiv.org/abs/1804.08313)
- Graph-to-Sequence Learning using Gated Graph Neural Networks [arxiv](https://arxiv.org/abs/1806.09835)
- Structural Neural Encoders for AMR-to-text Generation [arxiv](https://arxiv.org/abs/1903.11410)
- A Graph-to-Sequence Model for AMR-to-Text Generation [arxiv](https://arxiv.org/abs/1805.02473)
- Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks [arxiv](https://arxiv.org/abs/1804.00823)
- Knowledge Transfer for Out-of-Knowledge-Base Entities: A Graph Neural Network Approach [arxiv](https://arxiv.org/abs/1706.05674)
- Modeling Relational Data with Graph Convolutional Networks [arxiv](https://arxiv.org/abs/1703.06103)
- Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs [arxiv](https://arxiv.org/abs/1906.01195)
- End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion [arxiv](https://arxiv.org/abs/1811.04441)
- Knowledge Graph Convolutional Networks for Recommender Systems [arxiv](https://arxiv.org/abs/1904.12575)
- Graph Wavelet Neural Network [arxiv](https://arxiv.org/abs/1904.07785)
## 10.2節 意味役割のラベリング（SRL）
- Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling [arxiv](https://arxiv.org/abs/1703.04826)
- A Primer on Neural Network Models for Natural Language Processing [arxiv](https://arxiv.org/abs/1510.00726)
## 10.3節 ニューラル機械翻訳
- Neural Machine Translation by Jointly Learning to Align and Translate [arxiv](https://arxiv.org/abs/1409.0473)
- Attention Is All You Need [arxiv](https://arxiv.org/abs/1706.03762)
- BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [arxiv](https://arxiv.org/abs/1810.04805)
- Improving Language Understanding by Generative Pre-Training [リンク](https://paperswithcode.com/paper/improving-language-understanding-by)
- Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks [arxiv](https://arxiv.org/abs/1804.08313)
- Graph Convolutional Encoders for Syntax-aware Neural Machine Translation [arxiv](https://arxiv.org/abs/1704.04675)
## 10.4節 関係抽出
- Graph Convolution over Pruned Dependency Trees Improves Relation Extraction [arxiv](https://arxiv.org/abs/1809.10185)
- GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction [リンク](https://aclanthology.org/P19-1136/)
- Attention Guided Graph Convolutional Networks for Relation Extraction [arxiv](https://arxiv.org/abs/1906.07510)
- Graph Neural Networks with Generated Parameters for Relation Extraction [リンク](https://aclanthology.org/P19-1128/)
- Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network [arxiv](https://arxiv.org/abs/1906.04684)
- Joint Type Inference on Entities and Relations via Graph Convolutional Networks [リンク](https://aclanthology.org/P19-1131/)
- Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks [arxiv](https://arxiv.org/abs/1903.01306)
- Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling [arxiv](https://arxiv.org/abs/1703.04826)
## 10.5節 質問応答(QA)
- Question Answering by Reasoning Across Documents with Graph Convolutional Networks [arxiv](https://arxiv.org/abs/1808.09920)
- BAG: Bi-directional Attention Entity Graph Convolutional Network for Multi-hop Reasoning Question Answering [arxiv](https://arxiv.org/abs/1904.04969)
- Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks [arxiv](https://arxiv.org/abs/1809.02040)
- Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs [arxiv](https://arxiv.org/abs/1905.07374)
- Constructing Datasets for Multi-hop Reading Comprehension Across Documents [arxiv](https://arxiv.org/abs/1710.06481)
- End-to-end Neural Coreference Resolution [arxiv](https://arxiv.org/abs/1707.07045)
- Attention Is All You Need [arxiv](https://arxiv.org/abs/1706.03762)
- Deep contextualized word representations [arxiv](https://arxiv.org/abs/1802.05365)
## 10.6節 Graph-to-Sequence学習
- Neural Machine Translation by Jointly Learning to Align and Translate [arxiv](https://arxiv.org/abs/1409.0473)
- AMR-to-text Generation with Synchronous Node Replacement Grammar [arxiv](https://arxiv.org/abs/1702.00500)
- Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks [arxiv](https://arxiv.org/abs/1804.08313)
- Graph-to-Sequence Learning using Gated Graph Neural Networks [arxiv](https://arxiv.org/abs/1806.09835)
- Structural Neural Encoders for AMR-to-text Generation [arxiv](https://arxiv.org/abs/1903.11410)
- A Graph-to-Sequence Model for AMR-to-Text Generation [arxiv](https://arxiv.org/abs/1805.02473)
- Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling [arxiv](https://arxiv.org/abs/1703.04826)
- Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks [arxiv](https://arxiv.org/abs/1804.00823)
## 10.7節 知識グラフ上のGNN
- Knowledge Transfer for Out-of-Knowledge-Base Entities: A Graph Neural Network Approach [arxiv](https://arxiv.org/abs/1706.05674)
- Modeling Relational Data with Graph Convolutional Networks [arxiv](https://arxiv.org/abs/1703.06103)
- Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs [arxiv](https://arxiv.org/abs/1906.01195)
- End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion [arxiv](https://arxiv.org/abs/1811.04441)
- Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding [arxiv](https://arxiv.org/abs/1811.01399)
- Estimating Node Importance in Knowledge Graphs Using Graph Neural Networks [arxiv](https://arxiv.org/abs/1905.08865)
- OAG: Toward Linking Large-scale Heterogeneous Entity Graphs [リンク](https://www.stateoftheart.ai/papers/586cd1d4-6886-4c8f-99eb-3a7a43fa0235)
- Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks [リンク](https://aclanthology.org/D18-1032/)
- Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network [arxiv](https://arxiv.org/abs/1905.11605)
- Composition-based Multi-Relational Graph Convolutional Networks [arxiv](https://arxiv.org/abs/1911.03082)
- Learning Multi-Relational Semantics Using Neural-Embedding Models [arxiv](https://arxiv.org/abs/1411.4072)
## 10.9節 参考文献
- End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures [arxiv](https://arxiv.org/abs/1601.00770)
- N-ary Relation Extraction using Graph State LSTM [arxiv](https://arxiv.org/abs/1808.09101)
- Abusive Language Detection with Graph Convolutional Networks [arxiv](https://arxiv.org/abs/1904.04073)
- Structured Neural Summarization [arxiv](https://arxiv.org/abs/1811.01824)
- Attention Is All You Need [arxiv](https://arxiv.org/abs/1706.03762)
- BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding [arxiv](https://arxiv.org/abs/1810.04805)