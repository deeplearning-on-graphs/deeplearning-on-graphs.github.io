<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<title>参考文献リスト</title>
<link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.10.24/css/jquery.dataTables.css">
<script type="text/javascript" src="https://code.jquery.com/jquery-3.5.1.js"></script>
<script type="text/javascript" src="https://cdn.datatables.net/1.10.24/js/jquery.dataTables.js"></script>
<style>
    body {
        font-family: 'Verdana', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    h2 {
        color: #333;
    }
    table {
        width: 100%;
        max-width: 100%;
        border-collapse: collapse;
        margin-top: 20px;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }
    th, td {
        padding: 8px 10px;
        text-align: left;
        border-bottom: 1px solid #ddd;
        font-size: 11px;
    }
    th {
        background-color: #009879;
        color: #ffffff;
    }
    tr:hover {
        background-color: #f5f5f5;
    }
    /* 1番目の列の幅を48%に設定 */
    table.display td:nth-child(1),
    table.display th:nth-child(1) {
        width: 48%;
    }

    /* 2番目の列の幅を20%に設定 */
    table.display td:nth-child(2),
    table.display th:nth-child(2) {
        width: 20%;
    }
</style>
</head>
<body>

<a href="../">メインページ</a>

<h3>14.2節 深い層を持つGNN</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning</td>
      <td>Li et al</td>
      <td>2018b</td>
      <td><a href="https://arxiv.org/abs/1801.07606" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Spectral Graph Theory</td>
      <td>Chung and Graham</td>
      <td>1997</td>
      <td><a href="https://www.amazon.co.jp/dp/0821803158" target="_blank">amazon</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Graph Neural Networks Exponentially Lose Expressive Power for Node Classification</td>
      <td>Oono and Suzuki</td>
      <td>2020</td>
      <td><a href="https://arxiv.org/abs/1905.10947" target="_blank">arxiv</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Representation Learning on Graphs with Jumping Knowledge Networks</td>
      <td>Xu et al</td>
      <td>2018a</td>
      <td><a href="https://arxiv.org/abs/1806.03536" target="_blank">arxiv</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>DropEdge: Towards Deep Graph Convolutional Networks on Node Classification</td>
      <td>Rong et al</td>
      <td>2020</td>
      <td><a href="https://arxiv.org/abs/1907.10903" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>PairNorm: Tackling Oversmoothing in GNNs</td>
      <td>Zhao and Akoglu</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1909.12223" target="_blank">arxiv</a></td>
      <td>6</td>
    </tr>
  </tbody>
</table>
<h3>14.3節 自己教師あり学習</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Rethinking the Inception Architecture for Computer Vision</td>
      <td>Szegedy et al</td>
      <td>2016</td>
      <td><a href="https://arxiv.org/abs/1512.00567" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Very Deep Convolutional Networks for Large-Scale Image Recognition</td>
      <td>Simonyan and Zisserman</td>
      <td>2014</td>
      <td><a href="https://arxiv.org/abs/1409.1556" target="_blank">arxiv</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Language Models are Unsupervised Multitask Learners</td>
      <td>Radford et al</td>
      <td>2019</td>
      <td><a href="https://paperswithcode.com/paper/language-models-are-unsupervised-multitask" target="_blank">リンク</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</td>
      <td>Devlin et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1810.04805" target="_blank">arxiv</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Self-supervised Learning on Graphs: Deep Insights and New Direction</td>
      <td>Jin et al</td>
      <td>2020c</td>
      <td><a href="https://arxiv.org/abs/2006.10141" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>Pre-Training graph neural networks for generic structural feature extraction</td>
      <td>Hu et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1905.13728" target="_blank">arxiv</a></td>
      <td>6</td>
    </tr>
    <tr>
      <td>GPT-GNN: Generative Pre-Training of Graph Neural Networks</td>
      <td>Hu et al</td>
      <td>2020a</td>
      <td><a href="https://arxiv.org/abs/2006.15437" target="_blank">arxiv</a></td>
      <td>7</td>
    </tr>
    <tr>
      <td>Self-Supervised Graph Representation Learning via Global Context Prediction</td>
      <td>Peng et al</td>
      <td>2020</td>
      <td><a href="https://arxiv.org/abs/2003.01604" target="_blank">arxiv</a></td>
      <td>8</td>
    </tr>
    <tr>
      <td>A fast and high quality multilevel scheme for partitioning irregular graphs</td>
      <td>Karypis and Kumar</td>
      <td>1998</td>
      <td><a href="https://glaros.dtc.umn.edu/gkhome/node/107" target="_blank">リンク</a></td>
      <td>9</td>
    </tr>
    <tr>
      <td>Multi-Stage Self-Supervised Learning for Graph Convolutional Networks on Graphs with Few Labels</td>
      <td>Sun et al</td>
      <td>2019c</td>
      <td><a href="https://arxiv.org/abs/1902.11038" target="_blank">arxiv</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>When Does Self-Supervision Help Graph Convolutional Networks?</td>
      <td>You et al</td>
      <td>2020</td>
      <td><a href="https://arxiv.org/abs/2006.09136" target="_blank">arxiv</a></td>
      <td>11</td>
    </tr>
    <tr>
      <td>Semi-supervised learning using Gaussian fields and harmonic functions</td>
      <td>Zhu et al</td>
      <td>2003</td>
      <td><a href="https://dl.acm.org/doi/10.5555/3041838.3041953" target="_blank">リンク</a></td>
      <td>12</td>
    </tr>
    <tr>
      <td>Iterative Classification in Relational Data</td>
      <td>Neville and Jensen</td>
      <td>2000</td>
      <td><a href="https://aaai.org/papers/ws00-06-007-iterative-classification-in-relational-data/" target="_blank">リンク</a></td>
      <td>13</td>
    </tr>
    <tr>
      <td>Deep Self-Learning From Noisy Labels</td>
      <td>Han et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1908.02160" target="_blank">arxiv</a></td>
      <td>14</td>
    </tr>
    <tr>
      <td>Strategies for Pre-training Graph Neural Networks</td>
      <td>Hu et al</td>
      <td>2020b</td>
      <td><a href="https://arxiv.org/abs/1905.12265" target="_blank">arxiv</a></td>
      <td>15</td>
    </tr>
    <tr>
      <td>InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization</td>
      <td>Sun et al</td>
      <td>2019b</td>
      <td><a href="https://arxiv.org/abs/1908.01000" target="_blank">arxiv</a></td>
      <td>16</td>
    </tr>
  </tbody>
</table>
<h3>14.4節 グラフニューラルネットワークの表現力</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>How Powerful are Graph Neural Networks?</td>
      <td>Xu et al</td>
      <td>2019d</td>
      <td><a href="https://arxiv.org/abs/1810.00826" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>The reduction of a graph to canonical form and the algebra which appears therein</td>
      <td>Weisfeiler and Lehman</td>
      <td>1968</td>
      <td><a href="https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf" target="_blank">PDF</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Computers and Intractability: A Guide to the Theory of Np-Completeness</td>
      <td>Garey and Johnson</td>
      <td>1979</td>
      <td><a href="https://www.amazon.co.jp/dp/0716710455" target="_blank">amazon</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Graph Isomorphism in Quasipolynomial Time</td>
      <td>Babai</td>
      <td>2016</td>
      <td><a href="https://arxiv.org/abs/1512.03547" target="_blank">arxiv</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>An Optimal Lower Bound on the Number of Variables for Graph Identification</td>
      <td>Cai et al</td>
      <td>1992</td>
      <td><a href="https://people.cs.umass.edu/~immerman/pub/opt.pdf" target="_blank">PDF</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>Inductive Representation Learning on Large Graphs</td>
      <td>Hamilton et al</td>
      <td>2017a</td>
      <td><a href="https://arxiv.org/abs/1706.02216" target="_blank">arxiv</a></td>
      <td>6</td>
    </tr>
  </tbody>
</table>
<h3>14.6節 参考文献</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>GNNExplainer: Generating Explanations for Graph Neural Networks</td>
      <td>Ying et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1903.03894" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>XGNN: Towards Model-Level Explanations of Graph Neural Networks</td>
      <td>Yuan et al</td>
      <td>2020</td>
      <td><a href="https://arxiv.org/abs/2006.02587" target="_blank">arxiv</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Investigating and Mitigating Degree-Related Biases in Graph Convolutional Networks</td>
      <td>Tang et al</td>
      <td>2020</td>
      <td><a href="https://arxiv.org/abs/2006.15643" target="_blank">arxiv</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Hyperbolic Graph Convolutional Neural Networks</td>
      <td>Chami et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1910.12933" target="_blank">arxiv</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Hyperbolic Graph Neural Networks</td>
      <td>Liu et al</td>
      <td>2019a</td>
      <td><a href="https://arxiv.org/abs/1910.12892" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
  </tbody>
</table>

<script>
$(document).ready(function() {
    $('.display').DataTable({
     "lengthChange": false,  // Show 10 entriesの選択機能を非表示にする
     "pageLength": 20,  // ページごとに表示する行数を20行に設定
     "info": false,  // "Showing 1 to X of Y entries" の情報テキストを非表示にする
     "order": [],
     "searching": false
    });
});
</script>

<a href="../">メインページ</a>

</body>
</html>