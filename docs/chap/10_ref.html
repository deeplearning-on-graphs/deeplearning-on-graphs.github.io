<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<title>参考文献リスト</title>
<link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.10.24/css/jquery.dataTables.css">
<script type="text/javascript" src="https://code.jquery.com/jquery-3.5.1.js"></script>
<script type="text/javascript" src="https://cdn.datatables.net/1.10.24/js/jquery.dataTables.js"></script>
<style>
    body {
        font-family: 'Verdana', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    h2 {
        color: #333;
    }
    table {
        width: 100%;
        max-width: 100%;
        border-collapse: collapse;
        margin-top: 20px;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }
    th, td {
        padding: 8px 10px;
        text-align: left;
        border-bottom: 1px solid #ddd;
        font-size: 11px;
    }
    th {
        background-color: #009879;
        color: #ffffff;
    }
    tr:hover {
        background-color: #f5f5f5;
    }
    /* 1番目の列の幅を48%に設定 */
    table.display td:nth-child(1),
    table.display th:nth-child(1) {
        width: 48%;
    }

    /* 2番目の列の幅を20%に設定 */
    table.display td:nth-child(2),
    table.display th:nth-child(2) {
        width: 20%;
    }
</style>
</head>
<body>

<a href="../">メインページ</a>

<h3>10.1節 はじめに</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition</td>
      <td>Jurafsky and Martin</td>
      <td>2000</td>
      <td><a href="https://www.amazon.co.jp/dp/0130950696" target="_blank">amazon</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Abstract Meaning Representation for Sembanking</td>
      <td>Banarescu et al</td>
      <td>2013</td>
      <td><a href="https://aclanthology.org/W13-2322.pdf" target="_blank">PDF</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling</td>
      <td>Marcheggiani and Titov</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1703.04826" target="_blank">arxiv</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Question Answering by Reasoning Across Documents with Graph Convolutional Networks</td>
      <td>De Cao et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1808.09920" target="_blank">arxiv</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>BAG: Bi-directional Attention Entity Graph Convolutional Network for Multi-hop Reasoning Question Answering</td>
      <td>Cao et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1904.04969" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks</td>
      <td>Song et al</td>
      <td>2018a</td>
      <td><a href="https://arxiv.org/abs/1809.02040" target="_blank">arxiv</a></td>
      <td>6</td>
    </tr>
    <tr>
      <td>Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs</td>
      <td>Tu et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1905.07374" target="_blank">arxiv</a></td>
      <td>7</td>
    </tr>
    <tr>
      <td>Graph Convolution over Pruned Dependency Trees Improves Relation Extraction</td>
      <td>Zhang et al</td>
      <td>2018c</td>
      <td><a href="https://arxiv.org/abs/1809.10185" target="_blank">arxiv</a></td>
      <td>8</td>
    </tr>
    <tr>
      <td>GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction</td>
      <td>Fu et al</td>
      <td>2019</td>
      <td><a href="https://aclanthology.org/P19-1136/" target="_blank">リンク</a></td>
      <td>9</td>
    </tr>
    <tr>
      <td>Attention Guided Graph Convolutional Networks for Relation Extraction</td>
      <td>Guo et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1906.07510" target="_blank">arxiv</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>Graph Neural Networks with Generated Parameters for Relation Extraction</td>
      <td>Zhu et al</td>
      <td>2019b</td>
      <td><a href="https://aclanthology.org/P19-1128/" target="_blank">リンク</a></td>
      <td>11</td>
    </tr>
    <tr>
      <td>Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network</td>
      <td>Sahu et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1906.04684" target="_blank">arxiv</a></td>
      <td>12</td>
    </tr>
    <tr>
      <td>Joint Type Inference on Entities and Relations via Graph Convolutional Networks</td>
      <td>Sun et al</td>
      <td>2019a</td>
      <td><a href="https://aclanthology.org/P19-1131/" target="_blank">リンク</a></td>
      <td>13</td>
    </tr>
    <tr>
      <td>Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks</td>
      <td>Zhang et al</td>
      <td>2019d</td>
      <td><a href="https://arxiv.org/abs/1903.01306" target="_blank">arxiv</a></td>
      <td>14</td>
    </tr>
    <tr>
      <td>Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks</td>
      <td>Marcheggiani et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1804.08313" target="_blank">arxiv</a></td>
      <td>15</td>
    </tr>
    <tr>
      <td>Graph-to-Sequence Learning using Gated Graph Neural Networks</td>
      <td>Beck et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1806.09835" target="_blank">arxiv</a></td>
      <td>16</td>
    </tr>
    <tr>
      <td>Structural Neural Encoders for AMR-to-text Generation</td>
      <td>Cohen</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1903.11410" target="_blank">arxiv</a></td>
      <td>17</td>
    </tr>
    <tr>
      <td>A Graph-to-Sequence Model for AMR-to-Text Generation</td>
      <td>Song et al</td>
      <td>2018b</td>
      <td><a href="https://arxiv.org/abs/1805.02473" target="_blank">arxiv</a></td>
      <td>18</td>
    </tr>
    <tr>
      <td>Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks</td>
      <td>Xu et al</td>
      <td>2018b</td>
      <td><a href="https://arxiv.org/abs/1804.00823" target="_blank">arxiv</a></td>
      <td>19</td>
    </tr>
    <tr>
      <td>Knowledge Transfer for Out-of-Knowledge-Base Entities: A Graph Neural Network Approach</td>
      <td>Hamaguchi et al</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1706.05674" target="_blank">arxiv</a></td>
      <td>20</td>
    </tr>
    <tr>
      <td>Modeling Relational Data with Graph Convolutional Networks</td>
      <td>Schlichtkrull et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1703.06103" target="_blank">arxiv</a></td>
      <td>21</td>
    </tr>
    <tr>
      <td>Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</td>
      <td>Nathani et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1906.01195" target="_blank">arxiv</a></td>
      <td>22</td>
    </tr>
    <tr>
      <td>End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion</td>
      <td>Shang et al</td>
      <td>2019a</td>
      <td><a href="https://arxiv.org/abs/1811.04441" target="_blank">arxiv</a></td>
      <td>23</td>
    </tr>
    <tr>
      <td>Knowledge Graph Convolutional Networks for Recommender Systems</td>
      <td>Wang et al</td>
      <td>2019c</td>
      <td><a href="https://arxiv.org/abs/1904.12575" target="_blank">arxiv</a></td>
      <td>24</td>
    </tr>
    <tr>
      <td>Graph Wavelet Neural Network</td>
      <td>Xu et al</td>
      <td>2019a</td>
      <td><a href="https://arxiv.org/abs/1904.07785" target="_blank">arxiv</a></td>
      <td>25</td>
    </tr>
  </tbody>
</table>
<h3>10.2節 意味役割のラベリング（SRL）</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling</td>
      <td>Marcheggiani and Titov</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1703.04826" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>A Primer on Neural Network Models for Natural Language Processing</td>
      <td>Goldberg</td>
      <td>2016</td>
      <td><a href="https://arxiv.org/abs/1510.00726" target="_blank">arxiv</a></td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<h3>10.3節 ニューラル機械翻訳</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Neural Machine Translation by Jointly Learning to Align and Translate</td>
      <td>Bahdanau et al</td>
      <td>2014</td>
      <td><a href="https://arxiv.org/abs/1409.0473" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Attention Is All You Need</td>
      <td>Vaswani et al</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1706.03762" target="_blank">arxiv</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</td>
      <td>Devlin et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1810.04805" target="_blank">arxiv</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Improving Language Understanding by Generative Pre-Training</td>
      <td>Radford et al</td>
      <td>2018</td>
      <td><a href="https://paperswithcode.com/paper/improving-language-understanding-by" target="_blank">リンク</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks</td>
      <td>Marcheggiani et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1804.08313" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>Graph Convolutional Encoders for Syntax-aware Neural Machine Translation</td>
      <td>Bastings et al</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1704.04675" target="_blank">arxiv</a></td>
      <td>6</td>
    </tr>
  </tbody>
</table>
<h3>10.4節 関係抽出</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Graph Convolution over Pruned Dependency Trees Improves Relation Extraction</td>
      <td>Zhang et al</td>
      <td>2018c</td>
      <td><a href="https://arxiv.org/abs/1809.10185" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction</td>
      <td>Fu et al</td>
      <td>2019</td>
      <td><a href="https://aclanthology.org/P19-1136/" target="_blank">リンク</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Attention Guided Graph Convolutional Networks for Relation Extraction</td>
      <td>Guo et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1906.07510" target="_blank">arxiv</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Graph Neural Networks with Generated Parameters for Relation Extraction</td>
      <td>Zhu et al</td>
      <td>2019b</td>
      <td><a href="https://aclanthology.org/P19-1128/" target="_blank">リンク</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network</td>
      <td>Sahu et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1906.04684" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>Joint Type Inference on Entities and Relations via Graph Convolutional Networks</td>
      <td>Sun et al</td>
      <td>2019a</td>
      <td><a href="https://aclanthology.org/P19-1131/" target="_blank">リンク</a></td>
      <td>6</td>
    </tr>
    <tr>
      <td>Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks</td>
      <td>Zhang et al</td>
      <td>2019d</td>
      <td><a href="https://arxiv.org/abs/1903.01306" target="_blank">arxiv</a></td>
      <td>7</td>
    </tr>
    <tr>
      <td>Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling</td>
      <td>Marcheggiani and Titov</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1703.04826" target="_blank">arxiv</a></td>
      <td>8</td>
    </tr>
  </tbody>
</table>
<h3>10.5節 質問応答(QA)</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Question Answering by Reasoning Across Documents with Graph Convolutional Networks</td>
      <td>De Cao et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1808.09920" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>BAG: Bi-directional Attention Entity Graph Convolutional Network for Multi-hop Reasoning Question Answering</td>
      <td>Cao et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1904.04969" target="_blank">arxiv</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks</td>
      <td>Song et al</td>
      <td>2018a</td>
      <td><a href="https://arxiv.org/abs/1809.02040" target="_blank">arxiv</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs</td>
      <td>Tu et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1905.07374" target="_blank">arxiv</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Constructing Datasets for Multi-hop Reading Comprehension Across Documents</td>
      <td>Welbl et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1710.06481" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>End-to-end Neural Coreference Resolution</td>
      <td>Lee et al</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1707.07045" target="_blank">arxiv</a></td>
      <td>6</td>
    </tr>
    <tr>
      <td>Attention Is All You Need</td>
      <td>Vaswani et al</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1706.03762" target="_blank">arxiv</a></td>
      <td>7</td>
    </tr>
    <tr>
      <td>Deep contextualized word representations</td>
      <td>Peters et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1802.05365" target="_blank">arxiv</a></td>
      <td>8</td>
    </tr>
  </tbody>
</table>
<h3>10.6節 Graph-to-Sequence学習</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Neural Machine Translation by Jointly Learning to Align and Translate</td>
      <td>Bahdanau et al</td>
      <td>2014</td>
      <td><a href="https://arxiv.org/abs/1409.0473" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>AMR-to-text Generation with Synchronous Node Replacement Grammar</td>
      <td>Song et al</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1702.00500" target="_blank">arxiv</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks</td>
      <td>Marcheggiani et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1804.08313" target="_blank">arxiv</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Graph-to-Sequence Learning using Gated Graph Neural Networks</td>
      <td>Beck et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1806.09835" target="_blank">arxiv</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Structural Neural Encoders for AMR-to-text Generation</td>
      <td>Cohen</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1903.11410" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>A Graph-to-Sequence Model for AMR-to-Text Generation</td>
      <td>Song et al</td>
      <td>2018b</td>
      <td><a href="https://arxiv.org/abs/1805.02473" target="_blank">arxiv</a></td>
      <td>6</td>
    </tr>
    <tr>
      <td>Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling</td>
      <td>Marcheggiani and Titov</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1703.04826" target="_blank">arxiv</a></td>
      <td>7</td>
    </tr>
    <tr>
      <td>Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks</td>
      <td>Xu et al</td>
      <td>2018b</td>
      <td><a href="https://arxiv.org/abs/1804.00823" target="_blank">arxiv</a></td>
      <td>8</td>
    </tr>
  </tbody>
</table>
<h3>10.7節 知識グラフ上のGNN</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Knowledge Transfer for Out-of-Knowledge-Base Entities: A Graph Neural Network Approach</td>
      <td>Hamaguchi et al</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1706.05674" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>Modeling Relational Data with Graph Convolutional Networks</td>
      <td>Schlichtkrull et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1703.06103" target="_blank">arxiv</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</td>
      <td>Nathani et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1906.01195" target="_blank">arxiv</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion</td>
      <td>Shang et al</td>
      <td>2019a</td>
      <td><a href="https://arxiv.org/abs/1811.04441" target="_blank">arxiv</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Logic Attention Based Neighborhood Aggregation for Inductive Knowledge Graph Embedding</td>
      <td>Wang et al</td>
      <td>2019f</td>
      <td><a href="https://arxiv.org/abs/1811.01399" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>Estimating Node Importance in Knowledge Graphs Using Graph Neural Networks</td>
      <td>Park et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1905.08865" target="_blank">arxiv</a></td>
      <td>6</td>
    </tr>
    <tr>
      <td>OAG: Toward Linking Large-scale Heterogeneous Entity Graphs</td>
      <td>Zhang et al</td>
      <td>2019b</td>
      <td><a href="https://www.stateoftheart.ai/papers/586cd1d4-6886-4c8f-99eb-3a7a43fa0235" target="_blank">リンク</a></td>
      <td>7</td>
    </tr>
    <tr>
      <td>Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks</td>
      <td>Wang et al</td>
      <td>2018c</td>
      <td><a href="https://aclanthology.org/D18-1032/" target="_blank">リンク</a></td>
      <td>8</td>
    </tr>
    <tr>
      <td>Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network</td>
      <td>Xu et al</td>
      <td>2019e</td>
      <td><a href="https://arxiv.org/abs/1905.11605" target="_blank">arxiv</a></td>
      <td>9</td>
    </tr>
    <tr>
      <td>Composition-based Multi-Relational Graph Convolutional Networks</td>
      <td>Vashishth et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1911.03082" target="_blank">arxiv</a></td>
      <td>10</td>
    </tr>
    <tr>
      <td>Learning Multi-Relational Semantics Using Neural-Embedding Models</td>
      <td>Yang et al</td>
      <td>2014</td>
      <td><a href="https://arxiv.org/abs/1411.4072" target="_blank">arxiv</a></td>
      <td>11</td>
    </tr>
  </tbody>
</table>
<h3>10.9節 参考文献</h3>
<table class="dataframe display">
  <thead>
    <tr style="text-align: right;">
      <th>タイトル</th>
      <th>著者名</th>
      <th>年</th>
      <th>リンク</th>
      <th>節内順序</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures</td>
      <td>Miwa and Bansal</td>
      <td>2016</td>
      <td><a href="https://arxiv.org/abs/1601.00770" target="_blank">arxiv</a></td>
      <td>1</td>
    </tr>
    <tr>
      <td>N-ary Relation Extraction using Graph State LSTM</td>
      <td>Song et al</td>
      <td>2018c</td>
      <td><a href="https://arxiv.org/abs/1808.09101" target="_blank">arxiv</a></td>
      <td>2</td>
    </tr>
    <tr>
      <td>Abusive Language Detection with Graph Convolutional Networks</td>
      <td>Mishra et al</td>
      <td>2019</td>
      <td><a href="https://arxiv.org/abs/1904.04073" target="_blank">arxiv</a></td>
      <td>3</td>
    </tr>
    <tr>
      <td>Structured Neural Summarization</td>
      <td>Fernandes et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1811.01824" target="_blank">arxiv</a></td>
      <td>4</td>
    </tr>
    <tr>
      <td>Attention Is All You Need</td>
      <td>Vaswani et al</td>
      <td>2017</td>
      <td><a href="https://arxiv.org/abs/1706.03762" target="_blank">arxiv</a></td>
      <td>5</td>
    </tr>
    <tr>
      <td>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</td>
      <td>Devlin et al</td>
      <td>2018</td>
      <td><a href="https://arxiv.org/abs/1810.04805" target="_blank">arxiv</a></td>
      <td>6</td>
    </tr>
  </tbody>
</table>

<script>
$(document).ready(function() {
    $('.display').DataTable({
     "lengthChange": false,  // Show 10 entriesの選択機能を非表示にする
     "pageLength": 20,  // ページごとに表示する行数を20行に設定
     "info": false,  // "Showing 1 to X of Y entries" の情報テキストを非表示にする
     "order": [],
     "searching": false
    });
});
</script>

<a href="../">メインページ</a>

</body>
</html>